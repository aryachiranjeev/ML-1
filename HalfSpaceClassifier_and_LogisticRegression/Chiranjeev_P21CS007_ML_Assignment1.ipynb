{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment_a_b_c.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAdQ8HPucQJx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sugLzyIIcooT"
      },
      "source": [
        "BreastCancer = pd.read_csv(\"/content/BreastCancer.csv\")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "g_X8fqx7cqqR",
        "outputId": "773708cc-9527-4a52-8485-72183c3461a1"
      },
      "source": [
        "BreastCancer.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpwrIuzdcr5h",
        "outputId": "d3376bcd-046e-48ac-f7f6-78e82c318929"
      },
      "source": [
        "BreastCancer.isna().sum()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                           0\n",
              "diagnosis                    0\n",
              "radius_mean                  0\n",
              "texture_mean                 0\n",
              "perimeter_mean               0\n",
              "area_mean                    0\n",
              "smoothness_mean              0\n",
              "compactness_mean             0\n",
              "concavity_mean               0\n",
              "concave points_mean          0\n",
              "symmetry_mean                0\n",
              "fractal_dimension_mean       0\n",
              "radius_se                    0\n",
              "texture_se                   0\n",
              "perimeter_se                 0\n",
              "area_se                      0\n",
              "smoothness_se                0\n",
              "compactness_se               0\n",
              "concavity_se                 0\n",
              "concave points_se            0\n",
              "symmetry_se                  0\n",
              "fractal_dimension_se         0\n",
              "radius_worst                 0\n",
              "texture_worst                0\n",
              "perimeter_worst              0\n",
              "area_worst                   0\n",
              "smoothness_worst             0\n",
              "compactness_worst            0\n",
              "concavity_worst              0\n",
              "concave points_worst         0\n",
              "symmetry_worst               0\n",
              "fractal_dimension_worst      0\n",
              "Unnamed: 32                569\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpbxVzZMctf6",
        "outputId": "23d12d5c-033d-4ed1-cfdc-740c0eff4e45"
      },
      "source": [
        "print(len(BreastCancer.iloc[:,-1]))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRLgJ29Fcvrh"
      },
      "source": [
        "BreastCancer = BreastCancer.drop(['Unnamed: 32'], axis=1)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "CGhNey6ucxIK",
        "outputId": "57839b61-ca2c-41c1-fd26-df4f9114f352"
      },
      "source": [
        "BreastCancer"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0      842302         M  ...          0.4601                  0.11890\n",
              "1      842517         M  ...          0.2750                  0.08902\n",
              "2    84300903         M  ...          0.3613                  0.08758\n",
              "3    84348301         M  ...          0.6638                  0.17300\n",
              "4    84358402         M  ...          0.2364                  0.07678\n",
              "..        ...       ...  ...             ...                      ...\n",
              "564    926424         M  ...          0.2060                  0.07115\n",
              "565    926682         M  ...          0.2572                  0.06637\n",
              "566    926954         M  ...          0.2218                  0.07820\n",
              "567    927241         M  ...          0.4087                  0.12400\n",
              "568     92751         B  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 32 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_6APAhCcyVo"
      },
      "source": [
        "X1 = BreastCancer.iloc[:,2:].values\n",
        "Y = BreastCancer.iloc[:,1].values"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6Hy1j1fc0Mn"
      },
      "source": [
        "Y1 = []\n",
        "for i in range(len(Y)):\n",
        "  if Y[i] == 'M':\n",
        "    Y1.append(-1)\n",
        "  elif Y[i] == 'B':\n",
        "    Y1.append(1)\n",
        "    \n",
        "Y1 = np.array(Y1)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwpBjJJDc2T0",
        "outputId": "e69834a9-4b63-4c57-f432-dd4ffaf11692"
      },
      "source": [
        "print(X1.shape)\n",
        "print(Y1.shape)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si8MovTkyfkj"
      },
      "source": [
        "## **70:30 (train:test) split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qavD4JLNc4D-"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X1,Y1,test_size = 0.3,shuffle = True,random_state = 42)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD7qMuZ_c5cm",
        "outputId": "fd3aca34-ca78-4720-b0aa-69574a7e87d2"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(398, 30)\n",
            "(171, 30)\n",
            "(398,)\n",
            "(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4YMvxWA82vC"
      },
      "source": [
        "# Data Preprocessing for Half-Space Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rlxBq95-5mj",
        "outputId": "758e0385-6c2f-4211-9cdd-6c2a24e71ab7"
      },
      "source": [
        "X_Malign = []\n",
        "X_Benign = []\n",
        "Y_Malign = []\n",
        "Y_Benign = []\n",
        "\n",
        "for i in range(len(x_train)):\n",
        "\n",
        "  if y_train[i] == -1:\n",
        "    X_Malign.append(x_train[i])\n",
        "    Y_Malign.append(y_train[i])\n",
        "    \n",
        "  elif y_train[i] == 1:\n",
        "    X_Benign.append(x_train[i])\n",
        "    Y_Benign.append(y_train[i])\n",
        "\n",
        "X_Malign = np.array(X_Malign)\n",
        "X_Benign = np.array(X_Benign)\n",
        "\n",
        "print(X_Malign.shape)\n",
        "print(X_Benign.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 30)\n",
            "(248, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaKgg-9I87CZ",
        "outputId": "a2a05ab4-85a7-4b78-9049-eda5c2b0087c"
      },
      "source": [
        "def euclidean_distance(x1,c_):\n",
        "  \n",
        "  dist = np.sqrt(np.sum((x1-c_)**2))\n",
        "\n",
        "  return dist\n",
        "\n",
        "# centroidd of Malign data\n",
        "X_Malign_Centroid = X_Malign.mean(axis = 0)\n",
        "X_Benign_Centroid = X_Benign.mean(axis = 0)\n",
        "\n",
        "distance_Benign = []\n",
        "distance_Malign = []\n",
        "\n",
        "X_redundant_points = []\n",
        "Y_redundant_points = []\n",
        "\n",
        "X_sep= []\n",
        "Y_sep = []\n",
        "\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "\n",
        "  dist_Malign = euclidean_distance(x_train[i],X_Malign_Centroid) \n",
        "  dist_Benign = euclidean_distance(x_train[i],X_Benign_Centroid) \n",
        "\n",
        "  if y_train[i] == -1 and dist_Malign < dist_Benign and dist_Malign <= 1000: # -1:M, 1:B # correct\n",
        "\n",
        "    # X_Malign_sep.append(x_train[i])\n",
        "    # Y_Malign.append(y_train[i])\n",
        "    X_sep.append(x_train[i])\n",
        "    Y_sep.append(y_train[i])\n",
        "    distance_Malign.append(dist_Malign)\n",
        "  \n",
        "  elif y_train[i] == -1 and dist_Malign > dist_Benign: # incorrect\n",
        "    \n",
        "    X_redundant_points.append(x_train[i])\n",
        "    Y_redundant_points.append(y_train[i])\n",
        "\n",
        "\n",
        "  elif y_train[i] == 1 and dist_Benign < dist_Malign and dist_Benign <= 200  : # -1:M, 1:B # correct\n",
        "\n",
        "    # X_Malign_sep.append(x_train[i])\n",
        "    # Y_Malign.append(y_train[i])\n",
        "    X_sep.append(x_train[i])\n",
        "    Y_sep.append(y_train[i])\n",
        "    distance_Benign.append(dist_Benign)\n",
        "  \n",
        "  elif y_train[i] == 1 and dist_Benign > dist_Malign: # incorrect\n",
        "    \n",
        "    X_redundant_points.append(x_train[i])\n",
        "    Y_redundant_points.append(y_train[i])\n",
        "\n",
        "X_sep = np.array(X_sep)\n",
        "Y_sep = np.array(Y_sep)\n",
        "\n",
        "print(X_sep.shape)\n",
        "print(Y_sep.shape)\n",
        "\n",
        "  "
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(259, 30)\n",
            "(259,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L18TAlrZbQ5"
      },
      "source": [
        "# PCA "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_hAX-RBaiTO"
      },
      "source": [
        "PCA ON ORIGINAL DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "VyA7Ld0EaNW6",
        "outputId": "08ddfbec-7700-499e-e536-1854e861fd15"
      },
      "source": [
        "# PCA ON ORIGINAL DATASET\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(X1)\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
        "Y_df = pd.DataFrame(Y1,columns=['target'])\n",
        "finalDf = pd.concat([principalDf, Y_df[['target']]], axis = 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('2 component PCA', fontsize = 20)\n",
        "targets = [1,-1]\n",
        "colors = ['r', 'g']\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['target'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
        "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnv_-qsxafhF"
      },
      "source": [
        "PCA on Linearly Seperable Dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "wLWXf1ahEklA",
        "outputId": "3a7aaf41-9324-400b-9d18-20ec09ba95ab"
      },
      "source": [
        "# PCA on Linearly Seperable Dataset\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(X_sep)\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
        "Y_df = pd.DataFrame(Y_sep,columns=['target'])\n",
        "finalDf = pd.concat([principalDf, Y_df[['target']]], axis = 1)\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('2 component PCA', fontsize = 20)\n",
        "targets = [1,-1]\n",
        "colors = ['r', 'g']\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['target'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
        "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovk1Qnv9aoAf"
      },
      "source": [
        "# LP solver (scipy.optimize.linprog)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUiLo7G1FRor",
        "outputId": "7e46494f-ee3d-4835-a04d-2bbe25c9c110"
      },
      "source": [
        "from scipy.optimize import linprog\n",
        "A = []\n",
        "for i in range(len(X_sep)):\n",
        "  A.append(X_sep[i]*Y_sep[i]) \n",
        "A = -1*np.array(A)\n",
        "print(A.shape)\n",
        "\n",
        "V = -1*np.ones(len(Y_sep))\n",
        "V = np.reshape(V,(len(V),1))\n",
        "print(V.shape)\n",
        "\n",
        "\n",
        "obj = [0 for j in range(np.array(X_sep).shape[1])]\n",
        "\n",
        "lhs_ineq = []\n",
        "rhs_ineq = []\n",
        "\n",
        "for i in range(len(A)):\n",
        "  lhs_ineq.append(list(A[i]))\n",
        "  rhs_ineq.append(V[i])\n",
        "bnd=(None,None)\n",
        "opt = linprog(c=obj,A_ub=lhs_ineq,b_ub=rhs_ineq,bounds=bnd,method ='simplex',options={\"disp\": True})"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(259, 30)\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.000000    \n",
            "         Iterations: 465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "838Iww7-GYbG",
        "outputId": "340670bb-5084-4a13-f134-8486086e8420"
      },
      "source": [
        "opt"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     con: array([], dtype=float64)\n",
              "     fun: 0.0\n",
              " message: 'Optimization terminated successfully.'\n",
              "     nit: 465\n",
              "   slack: array([ 4.55846783e+00,  4.61294724e+00,  8.10811908e+00,  1.05742802e+01,\n",
              "        3.43878600e+00,  5.96607612e+00,  7.47689088e+00,  5.49048206e+00,\n",
              "        6.54960099e+00,  2.31640172e+00,  5.68261840e+00,  2.17527111e+01,\n",
              "        4.44445280e+00,  7.62229828e+00,  3.92917886e+00,  7.65615781e+00,\n",
              "        3.13152726e+00,  1.39253040e+01,  3.55324696e+00,  8.69201756e+00,\n",
              "       -2.27373675e-13,  3.20960756e+00, -4.19220214e-13,  2.25095560e+01,\n",
              "        3.50499382e+00,  3.64300809e+00,  1.55874142e+00,  7.06407970e+00,\n",
              "        9.30559621e-01,  2.78984603e+00,  5.71829155e+00,  3.69856599e+00,\n",
              "        1.07155158e+01,  6.88858115e+00,  2.53023396e+00,  2.90950410e+00,\n",
              "       -1.31450406e-13,  5.41265068e+00,  3.69379063e+00,  4.91118532e+00,\n",
              "        2.67584395e+00,  4.55312437e+00,  5.20317810e+00,  4.85965293e+00,\n",
              "        4.61611773e+00, -3.48165941e-13,  2.76626836e+00,  1.75652908e+01,\n",
              "        9.75929180e+00,  4.97069750e+00,  1.94906331e+00,  5.68938993e+00,\n",
              "        3.25487524e+00,  6.58710711e+00,  2.22770017e+01,  6.14747693e-01,\n",
              "        2.35032841e+00,  1.02564304e+01,  5.02111870e+00,  3.81623848e+00,\n",
              "        1.61978927e+00,  3.93352365e+00,  4.70084814e+00,  1.82771464e+00,\n",
              "        5.99348150e+00,  3.32903912e+00,  6.60167308e+00,  1.32595536e+01,\n",
              "        4.09168971e+00,  6.70831511e+00, -1.24344979e-13,  3.50817726e+00,\n",
              "        2.00767652e+00,  2.00352100e+00,  3.83075920e+00, -2.41584530e-13,\n",
              "        2.97182084e+00,  1.76218527e+01,  1.19332212e+01,  1.36846925e+00,\n",
              "        5.01647342e+00,  9.84097946e+00,  4.50102656e+00,  1.51765299e+01,\n",
              "        1.73233519e+00,  4.74735571e+00,  5.93475172e+00,  3.75441007e+00,\n",
              "        9.42465820e+00,  5.25776056e+00,  2.16930290e+00,  6.87426179e+00,\n",
              "        6.32535334e+00,  1.42184112e+00,  3.68390422e+00,  1.23886128e+01,\n",
              "        6.69476158e-01,  7.52208552e+00,  1.17622105e+01,  3.46283681e+00,\n",
              "        7.18974726e+00,  2.24608176e+00,  1.82402337e+00,  1.88976498e+00,\n",
              "        1.10652881e+01,  4.81366182e+00,  9.15449402e+00,  3.96739892e+00,\n",
              "        1.37523173e+00,  6.73153419e+00,  1.21968852e+01,  1.07662064e+00,\n",
              "        4.00125629e+00,  3.14138949e+00,  3.10688176e+00,  3.29364673e-01,\n",
              "        2.42483225e+00,  4.48071764e+00,  3.21624401e+00,  3.81256080e+00,\n",
              "        4.12360904e+00,  8.86484044e+00,  3.46411625e+00,  1.27897692e-13,\n",
              "        1.28097351e+01,  3.47146406e+00,  1.63467490e+01,  1.15204922e+00,\n",
              "        1.62371219e+01,  7.52001184e+00,  4.83182782e+00,  4.20255990e+00,\n",
              "        2.80909384e+00,  2.16825827e+00,  2.97029739e+00,  1.45640458e+00,\n",
              "        6.10387473e+00,  1.76998838e+00,  3.81686885e+00,  3.44955155e+00,\n",
              "        1.47846084e+01,  1.33225416e+00,  5.55727438e+00,  5.76548523e+00,\n",
              "        2.90257606e+00,  1.37692836e+01,  5.44057542e+00,  1.57227450e+00,\n",
              "        3.06808765e+00,  2.66896994e+00,  6.30563651e+00,  5.61889841e+00,\n",
              "        2.91443385e+00,  4.88827281e+00,  9.38035501e+00,  9.61107127e-01,\n",
              "        1.85606815e+00,  8.50145926e+00,  2.07226107e+00,  3.90351688e+00,\n",
              "        1.63955717e+00,  5.83438610e+00,  1.76470654e+01,  7.17749217e+00,\n",
              "        4.58261339e+00,  8.52651283e-14,  7.57897505e-01,  9.53851629e+00,\n",
              "        5.89438503e-01,  3.45393391e+00,  3.30393693e+00,  1.69939443e+00,\n",
              "        4.66232253e+00,  3.28559132e+00,  9.23589348e+00,  8.94981592e+00,\n",
              "        3.45183476e+00,  8.66193686e-01,  5.72499651e+00,  1.00268561e+01,\n",
              "        4.17406518e+00,  4.51841817e+00,  4.06511747e+00,  1.60619475e+00,\n",
              "        7.46069873e-14,  3.54503003e+00,  4.97065749e+00,  3.07469959e+00,\n",
              "        2.61253703e-01,  1.36513902e+00,  1.54318322e+01,  1.84535936e+01,\n",
              "        8.07938542e-01,  1.54551575e+00,  2.32575494e+00,  9.96936670e-01,\n",
              "        1.27071870e+01,  3.77407724e+00,  5.99259078e+00,  1.41417714e+01,\n",
              "        8.17124146e-14,  4.01408901e+00,  1.41213301e+00,  3.69465355e+00,\n",
              "        1.92657969e+00,  1.49605247e+01,  5.56364353e+00,  2.68498673e+00,\n",
              "        1.61317932e+01,  9.77552701e-01,  8.63894127e+00,  9.79044645e+00,\n",
              "        3.97795294e+00,  3.87055425e+00,  3.88642340e+00,  4.53334632e+00,\n",
              "        4.43286137e+00,  3.72582133e+00,  6.47792673e+00,  1.68864494e+01,\n",
              "        1.48268778e+00,  6.72297352e+00,  1.95804613e+00,  4.22695084e+00,\n",
              "        5.19870434e+00,  4.59714584e-01,  2.39449760e+00,  3.58262104e+00,\n",
              "        7.97273259e+00,  5.06895954e+00,  1.40738830e+01,  2.94692349e+00,\n",
              "        3.04288991e+00,  3.88986834e+00,  5.45087998e+00,  2.95758745e+00,\n",
              "        4.29407292e+00,  5.50256494e+00,  1.71990876e+01,  4.29147300e+00,\n",
              "        1.09539057e+00,  3.26425912e+00,  7.23892725e-01,  3.89325938e+00,\n",
              "        6.42320349e+00,  3.20543092e+00,  1.14970849e+01,  6.07717976e+00,\n",
              "        6.84303733e+00,  2.89669551e+00,  1.66660424e+00,  2.13144764e+00,\n",
              "        1.12292576e+01,  3.48383986e+00,  3.64712215e+00,  4.80562225e+00,\n",
              "        1.45514408e+00,  1.67849874e+00,  8.46054765e+00])\n",
              "  status: 0\n",
              " success: True\n",
              "       x: array([ 0.00000000e+00,  2.42017048e-01,  2.75385963e-02,  3.22671907e-03,\n",
              "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.29805629e+00,\n",
              "        3.19831709e+00, -1.24449799e-01,  0.00000000e+00,  0.00000000e+00,\n",
              "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "        4.68557129e+00, -1.41516982e-01, -5.55155302e-01, -2.76066619e-02,\n",
              "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "        0.00000000e+00,  0.00000000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JOzzANwFXi1",
        "outputId": "feeb59f7-d35e-4b7f-8d8a-cf70088d8d1d"
      },
      "source": [
        "weights = opt['x']\n",
        "print(weights.shape)\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZyGWTB-FmO1",
        "outputId": "1b7c3bf2-27d0-4ba0-c3b6-5237618f1699"
      },
      "source": [
        "optimized_weights = []\n",
        "for i in weights:\n",
        "  optimized_weights.append(i)\n",
        "optimized_weights = np.array(optimized_weights)\n",
        "\n",
        "y_pred_train_lp = np.sign(np.matmul(X_sep,optimized_weights))\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_train_lp)):\n",
        "  if y_pred_train_lp[i] == Y_sep[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "y_pred_train_acc_lp = []\n",
        "y_train_acc_lp = []\n",
        "for i in range(len(y_pred_train_lp)):\n",
        "\n",
        "  if y_pred_train_lp[i] == -1:\n",
        "    y_pred_train_acc_lp.append(-1)\n",
        "  if y_pred_train_lp[i] == 1:\n",
        "    y_pred_train_acc_lp.append(1)\n",
        "\n",
        "  if Y_sep[i] == -1:\n",
        "    y_train_acc_lp.append(-1)\n",
        "  \n",
        "  if Y_sep[i] == 1:\n",
        "    y_train_acc_lp.append(1)\n",
        "\n",
        "y_pred_train_acc_lp = np.array(y_pred_train_acc_lp)\n",
        "y_train_acc_lp = np.array(y_train_acc_lp)\n",
        "# print(y_pred_train_acc_lp)\n",
        "# print(y_train_acc_lp)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "259\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjFodEc0bviv",
        "outputId": "b8a573c0-ff6e-4f42-bc6f-690c25c6aa8f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train_acc_lp, y_pred_train_acc_lp).ravel()\n",
        "training_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lp:\",training_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[ 98   0]\n",
            " [  0 161]]\n",
            "98 0 0 161\n",
            "training accuracy_lp: 100.0 %\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4hJGMyTcSuj",
        "outputId": "ea521b78-0a90-4716-e79f-ccb2347b4799"
      },
      "source": [
        "y_pred_test_lp = np.sign(np.matmul(x_test,optimized_weights))\n",
        "# y_test_true = np.array(y_test)\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "  if y_pred_test_lp[i] == y_test[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41LUa78hcfLj"
      },
      "source": [
        "y_pred_test_acc_lp = []\n",
        "y_test_acc_lp = []\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "\n",
        "  if y_pred_test_lp[i] == -1:\n",
        "    y_pred_test_acc_lp.append(-1)\n",
        "  if y_pred_test_lp[i] == 1:\n",
        "    y_pred_test_acc_lp.append(1)\n",
        "\n",
        "  if y_test[i] == -1:\n",
        "    y_test_acc_lp.append(-1)\n",
        "  \n",
        "  if y_test[i] == 1:\n",
        "    y_test_acc_lp.append(1)\n",
        "\n",
        "y_pred_test_acc_lp = np.array(y_pred_test_acc_lp)\n",
        "y_test_acc_lp = np.array(y_test_acc_lp)\n",
        "# print(y_pred_test_acc_lp)\n",
        "# print(y_test_acc_lp)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thwMTtmTdc6t",
        "outputId": "9612ceac-1d35-493c-e658-6061dbc4f9c9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test_acc_lp, y_pred_test_acc_lp).ravel()\n",
        "testing_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lp:\",testing_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[ 54   8]\n",
            " [  4 105]]\n",
            "54 8 4 105\n",
            "testing accuracy_lp: 92.98245614035088 %\n",
            "0.9298245614035088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu1UZ2ou01eI"
      },
      "source": [
        "# Perceptron (Half Space Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlaN-JblKKLL",
        "outputId": "9ae6a69e-95bb-42cf-deca-127b40a35840"
      },
      "source": [
        "def perceptron(x_train,y_train):\n",
        "\n",
        "  weights = np.zeros(x_train.shape[1])\n",
        "  \n",
        "  flag = 0\n",
        "  t = 0\n",
        "  while(flag == 0):\n",
        "  # for t in range(num_iterations):\n",
        "    flag = 1\n",
        "    for i in range(len(x_train)):\n",
        "      if y_train[i]*np.sum(x_train[i]*weights) <= 0:\n",
        "        flag = 0\n",
        "        weights = weights + y_train[i]*x_train[i]\n",
        "    # print(weights)\n",
        "    t+=1\n",
        "\n",
        "  return weights,t\n",
        "  \n",
        "w,t = perceptron(X_sep,Y_sep)\n",
        "print(w,t)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.0329800e+03  4.2675100e+03  1.2185230e+04  2.0381000e+03\n",
            "  2.2155680e+01  5.8134400e+00 -1.7549723e+01 -9.0573230e+00\n",
            "  4.3144900e+01  1.6527670e+01  2.2489000e+01  2.7913280e+02\n",
            "  1.7323000e+01 -3.2208510e+03  1.2049780e+00  6.9976900e-01\n",
            " -9.5412200e-02  5.8586900e-01  4.1961700e+00  3.0199500e-01\n",
            "  2.1799600e+03  5.9868800e+03  1.2871370e+04 -4.9402000e+03\n",
            "  3.0781760e+01  1.6491260e+01 -1.3634749e+01  5.2087000e-01\n",
            "  6.6059200e+01  1.9115710e+01] 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HLUXj11hWCi",
        "outputId": "02d560a7-a5d5-48d7-85d1-79bb468339b8"
      },
      "source": [
        "print(\"weights:\\n\",w,\"\\n num_of_iterations:\",t)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights:\n",
            " [ 2.0329800e+03  4.2675100e+03  1.2185230e+04  2.0381000e+03\n",
            "  2.2155680e+01  5.8134400e+00 -1.7549723e+01 -9.0573230e+00\n",
            "  4.3144900e+01  1.6527670e+01  2.2489000e+01  2.7913280e+02\n",
            "  1.7323000e+01 -3.2208510e+03  1.2049780e+00  6.9976900e-01\n",
            " -9.5412200e-02  5.8586900e-01  4.1961700e+00  3.0199500e-01\n",
            "  2.1799600e+03  5.9868800e+03  1.2871370e+04 -4.9402000e+03\n",
            "  3.0781760e+01  1.6491260e+01 -1.3634749e+01  5.2087000e-01\n",
            "  6.6059200e+01  1.9115710e+01] \n",
            " num_of_iterations: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slGV_9paKR38",
        "outputId": "8e76d5bd-55a4-47cb-9c23-b94972f02e13"
      },
      "source": [
        "y_pred_train_per = np.sign(np.matmul(X_sep,w))\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_train_per)):\n",
        "  if y_pred_train_per[i] == Y_sep[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "259\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r4chVe_itu5"
      },
      "source": [
        "y_pred_train_acc_lp = []\n",
        "y_train_acc_lp = []\n",
        "for i in range(len(y_pred_train_lp)):\n",
        "\n",
        "  if y_pred_train_lp[i] == -1:\n",
        "    y_pred_train_acc_lp.append(-1)\n",
        "  if y_pred_train_lp[i] == 1:\n",
        "    y_pred_train_acc_lp.append(1)\n",
        "\n",
        "  if Y_sep[i] == -1:\n",
        "    y_train_acc_lp.append(-1)\n",
        "  \n",
        "  if Y_sep[i] == 1:\n",
        "    y_train_acc_lp.append(1)\n",
        "\n",
        "y_pred_train_acc_lp = np.array(y_pred_train_acc_lp)\n",
        "y_train_acc_lp = np.array(y_train_acc_lp)\n",
        "# print(y_pred_train_acc_lp)\n",
        "# print(y_train_acc_lp)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-DlCaIQjPMc",
        "outputId": "2987f0b3-d53e-40d7-9664-a67d2b262561"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train_acc_lp, y_pred_train_acc_lp).ravel()\n",
        "training_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lp:\",training_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[ 98   0]\n",
            " [  0 161]]\n",
            "98 0 0 161\n",
            "training accuracy_lp: 100.0 %\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxqjtXlIjQ4-",
        "outputId": "3c9152d3-c28b-4966-c8b8-3714ec5fd2e1"
      },
      "source": [
        "y_pred_test_lp = np.sign(np.matmul(x_test,w))\n",
        "# y_test_true = np.array(y_test)\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "  if y_pred_test_lp[i] == y_test[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpV0P2lGjowo"
      },
      "source": [
        "y_pred_test_acc_lp = []\n",
        "y_test_acc_lp = []\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "\n",
        "  if y_pred_test_lp[i] == -1:\n",
        "    y_pred_test_acc_lp.append(-1)\n",
        "  if y_pred_test_lp[i] == 1:\n",
        "    y_pred_test_acc_lp.append(1)\n",
        "\n",
        "  if y_test[i] == -1:\n",
        "    y_test_acc_lp.append(-1)\n",
        "  \n",
        "  if y_test[i] == 1:\n",
        "    y_test_acc_lp.append(1)\n",
        "\n",
        "y_pred_test_acc_lp = np.array(y_pred_test_acc_lp)\n",
        "y_test_acc_lp = np.array(y_test_acc_lp)\n",
        "# print(y_pred_test_acc_lp)\n",
        "# print(y_test_acc_lp)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7OoXaZYjtnQ",
        "outputId": "7df231da-9142-4ade-b23a-8bf318a438c2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test_acc_lp, y_pred_test_acc_lp).ravel()\n",
        "testing_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lp:\",testing_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[ 54   8]\n",
            " [  4 105]]\n",
            "54 8 4 105\n",
            "testing accuracy_lp: 92.98245614035088 %\n",
            "0.9298245614035088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4IfRU-F1KBl"
      },
      "source": [
        "# Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTVlddRL4Edz"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjql0lL-4zAg",
        "outputId": "5686e8e9-811b-4d9c-e672-7e397e4a6ca3"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(398, 30)\n",
            "(398,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TGma_KHLxKn"
      },
      "source": [
        "x0 = np.ones(len(x_train))\n",
        "x0 = np.reshape(x0,(len(x0),1))\n",
        "x_training = np.hstack((x0,x_train))\n",
        "x0 = np.ones(len(x_test))\n",
        "x0 = np.reshape(x0,(len(x0),1))\n",
        "x_testing = np.hstack((x0,x_test))"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIElaq4s4g53",
        "outputId": "7bedb9d2-0dd5-416b-fc62-6e4f2a2cd041"
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "\n",
        "\n",
        "def helper_conversion(y_pred,y_true):\n",
        "\n",
        "    y_pred_help = []\n",
        "    y_true_help = []\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "\n",
        "      if y_pred[i] == -1:\n",
        "        y_pred_help.append(-1)\n",
        "      if y_pred[i] == 1:\n",
        "        y_pred_help.append(1)\n",
        "\n",
        "      #### beacuse initially weights = 0 and when predicted with x get value = 0 ######\n",
        "      if y_pred[i] == 0:\n",
        "        y_pred_help.append(0)\n",
        "\n",
        "\n",
        "\n",
        "      if y_true[i] == -1:\n",
        "        y_true_help.append(-1)\n",
        "      \n",
        "      if y_true[i] == 1:\n",
        "        y_true_help.append(1)\n",
        "\n",
        "    y_pred_help = np.array(y_pred_help)\n",
        "    y_true_help = np.array(y_true_help)\n",
        "\n",
        "    return y_pred_help,y_true_help\n",
        "\n",
        "\n",
        "def predict(x,theta):\n",
        "\n",
        "  y_pred = []\n",
        "  for i in range(len(x)):\n",
        "    pred = np.dot(x[i],theta)\n",
        "\n",
        "    y_pred.append(np.sign(pred))\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "\n",
        "def loss_function(x1,y1,theta1):\n",
        "\n",
        "  return np.log(1+np.exp(-y1*np.dot(x1,theta1)))\n",
        "\n",
        "\n",
        "\n",
        "def gradient_descent(x,y,theta,alpha):\n",
        "\n",
        "  loss = 0.0\n",
        "  temp=np.zeros_like(theta)\n",
        "\n",
        "\n",
        "  for i in range(len(x)):\n",
        "\n",
        "      temp[0] = theta[0] - alpha * 1/len(x) * -y[i] * 1 * np.exp(-y[i]*np.dot(x[i],theta)) * (1/(1+np.exp(-y[i]*np.dot(x[i],theta))))\n",
        "\n",
        "      for j in range(len(theta)-1):\n",
        "\n",
        "        gradient = -y[i] * x[i][j] * np.exp(-y[i]*np.dot(x[i],theta)) * (1/(1+np.exp(-y[i]*np.dot(x[i],theta))))\n",
        "      \n",
        "        temp[j+1] = theta[j+1] - alpha * 1/len(x) * gradient\n",
        "      \n",
        "      temp = theta\n",
        "      loss += loss_function(x[i],y[i],theta)\n",
        "\n",
        "  loss = (1/len(x)) * loss\n",
        "  return loss,theta\n",
        "\n",
        "  \n",
        "def fit(x,y,theta,alpha,epochs):\n",
        "\n",
        "  losses_per_epoch = []\n",
        "  accuracies_per_epoch = []\n",
        "\n",
        "  for e in range(1,epochs):\n",
        "    \n",
        "      loss,theta = gradient_descent(x,y,theta,alpha)\n",
        "      y_pred_training = predict(x,theta)\n",
        "      y_pred_help,y_true_help = helper_conversion(y_pred_training,y)\n",
        "      accuracy = accuracy_score(y_true = y_true_help, y_pred = y_pred_help)\n",
        "\n",
        "      print(\"epoch:\",e,\"loss:\",loss,\"accuracy:\",accuracy)#,\"weights:\",theta)\n",
        "      losses_per_epoch.append(loss)\n",
        "      accuracies_per_epoch.append(accuracy)  \n",
        "\n",
        "  \n",
        "  return loss,theta,losses_per_epoch,accuracies_per_epoch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "theta = [0.0 for t in range(0,x_train.shape[1]+1)]\n",
        "\n",
        "alpha =  0.001\n",
        "\n",
        "initial_loss = 0.0\n",
        "for i in range(len(x_training)):\n",
        "  initial_loss += loss_function(x_training[i],y_train[i],theta)\n",
        "\n",
        "# print(initial_loss)\n",
        "\n",
        "y_pred_training = predict(x_training,theta)\n",
        "y_pred_help,y_true_help = helper_conversion(y_pred_training,y_train)\n",
        "initial_accuracy = accuracy_score(y_true = y_true_help, y_pred = y_pred_help)\n",
        "\n",
        "\n",
        "print(\"epoch:\",0,\"loss:\",initial_loss/len(x_training),\"accuracy:\",initial_accuracy)\n",
        "\n",
        "\n",
        "loss_to_plot = []\n",
        "accuracy_to_plot = []\n",
        "loss_to_plot.append(initial_loss/len(x_training))\n",
        "accuracy_to_plot.append(0.0)\n",
        "\n",
        "num_of_epochs = 200\n",
        "loss,theta,losses_per_epoch,accuracies_per_epoch = fit(x_training,y_train,theta,alpha,num_of_epochs)\n",
        "loss_to_plot = loss_to_plot + losses_per_epoch\n",
        "accuracy_to_plot = accuracy_to_plot + accuracies_per_epoch\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: 0.6931471805599467 accuracy: 0.0\n",
            "epoch: 1 loss: 0.604866987331998 accuracy: 0.6306532663316583\n",
            "epoch: 2 loss: 0.5796302706913704 accuracy: 0.6834170854271356\n",
            "epoch: 3 loss: 0.5580779833282106 accuracy: 0.7638190954773869\n",
            "epoch: 4 loss: 0.5390989699735352 accuracy: 0.7964824120603015\n",
            "epoch: 5 loss: 0.5222350255689074 accuracy: 0.8241206030150754\n",
            "epoch: 6 loss: 0.5071319999732286 accuracy: 0.8316582914572864\n",
            "epoch: 7 loss: 0.4935061650708161 accuracy: 0.8567839195979899\n",
            "epoch: 8 loss: 0.48113105568499376 accuracy: 0.8693467336683417\n",
            "epoch: 9 loss: 0.4698262063633602 accuracy: 0.8693467336683417\n",
            "epoch: 10 loss: 0.45944713232292395 accuracy: 0.871859296482412\n",
            "epoch: 11 loss: 0.4498770714484828 accuracy: 0.8768844221105527\n",
            "epoch: 12 loss: 0.44102044542927255 accuracy: 0.8894472361809045\n",
            "epoch: 13 loss: 0.4327978524962548 accuracy: 0.8944723618090452\n",
            "epoch: 14 loss: 0.4251423489094182 accuracy: 0.8969849246231156\n",
            "epoch: 15 loss: 0.4179967426118787 accuracy: 0.8994974874371859\n",
            "epoch: 16 loss: 0.41131163301067425 accuracy: 0.9045226130653267\n",
            "epoch: 17 loss: 0.40504397608731696 accuracy: 0.9020100502512562\n",
            "epoch: 18 loss: 0.3991560103028578 accuracy: 0.9020100502512562\n",
            "epoch: 19 loss: 0.39361442942540475 accuracy: 0.9020100502512562\n",
            "epoch: 20 loss: 0.3883897270653891 accuracy: 0.8994974874371859\n",
            "epoch: 21 loss: 0.3834556643417373 accuracy: 0.9020100502512562\n",
            "epoch: 22 loss: 0.378788829274998 accuracy: 0.9020100502512562\n",
            "epoch: 23 loss: 0.3743682671283421 accuracy: 0.9020100502512562\n",
            "epoch: 24 loss: 0.3701751673744601 accuracy: 0.9020100502512562\n",
            "epoch: 25 loss: 0.36619259691623135 accuracy: 0.9020100502512562\n",
            "epoch: 26 loss: 0.3624052716823355 accuracy: 0.9020100502512562\n",
            "epoch: 27 loss: 0.35879936037749205 accuracy: 0.8994974874371859\n",
            "epoch: 28 loss: 0.3553623153416353 accuracy: 0.9020100502512562\n",
            "epoch: 29 loss: 0.35208272635487065 accuracy: 0.9020100502512562\n",
            "epoch: 30 loss: 0.34895019391957055 accuracy: 0.9020100502512562\n",
            "epoch: 31 loss: 0.3459552191143378 accuracy: 0.9020100502512562\n",
            "epoch: 32 loss: 0.3430891075797169 accuracy: 0.9045226130653267\n",
            "epoch: 33 loss: 0.3403438855828931 accuracy: 0.9045226130653267\n",
            "epoch: 34 loss: 0.33771222643237603 accuracy: 0.9045226130653267\n",
            "epoch: 35 loss: 0.3351873857844463 accuracy: 0.9045226130653267\n",
            "epoch: 36 loss: 0.332763144609656 accuracy: 0.9045226130653267\n",
            "epoch: 37 loss: 0.33043375877699716 accuracy: 0.9045226130653267\n",
            "epoch: 38 loss: 0.3281939143716906 accuracy: 0.9045226130653267\n",
            "epoch: 39 loss: 0.3260386879949294 accuracy: 0.907035175879397\n",
            "epoch: 40 loss: 0.32396351140479757 accuracy: 0.907035175879397\n",
            "epoch: 41 loss: 0.3219641399505435 accuracy: 0.907035175879397\n",
            "epoch: 42 loss: 0.32003662433051294 accuracy: 0.907035175879397\n",
            "epoch: 43 loss: 0.3181772852698484 accuracy: 0.907035175879397\n",
            "epoch: 44 loss: 0.31638269076962305 accuracy: 0.907035175879397\n",
            "epoch: 45 loss: 0.31464963562614534 accuracy: 0.9045226130653267\n",
            "epoch: 46 loss: 0.3129751229591362 accuracy: 0.907035175879397\n",
            "epoch: 47 loss: 0.3113563475215524 accuracy: 0.9045226130653267\n",
            "epoch: 48 loss: 0.30979068059290193 accuracy: 0.9045226130653267\n",
            "epoch: 49 loss: 0.30827565628286696 accuracy: 0.9045226130653267\n",
            "epoch: 50 loss: 0.3068089590934611 accuracy: 0.9045226130653267\n",
            "epoch: 51 loss: 0.30538841260642857 accuracy: 0.9045226130653267\n",
            "epoch: 52 loss: 0.3040119691785638 accuracy: 0.9020100502512562\n",
            "epoch: 53 loss: 0.30267770054144216 accuracy: 0.9045226130653267\n",
            "epoch: 54 loss: 0.30138378921409276 accuracy: 0.9045226130653267\n",
            "epoch: 55 loss: 0.30012852064757534 accuracy: 0.9045226130653267\n",
            "epoch: 56 loss: 0.2989102760295686 accuracy: 0.9045226130653267\n",
            "epoch: 57 loss: 0.29772752568505984 accuracy: 0.9045226130653267\n",
            "epoch: 58 loss: 0.29657882301619826 accuracy: 0.9045226130653267\n",
            "epoch: 59 loss: 0.2954627989305499 accuracy: 0.907035175879397\n",
            "epoch: 60 loss: 0.2943781567123637 accuracy: 0.907035175879397\n",
            "epoch: 61 loss: 0.29332366729625275 accuracy: 0.907035175879397\n",
            "epoch: 62 loss: 0.292298164906871 accuracy: 0.907035175879397\n",
            "epoch: 63 loss: 0.29130054303191544 accuracy: 0.907035175879397\n",
            "epoch: 64 loss: 0.29032975069906497 accuracy: 0.907035175879397\n",
            "epoch: 65 loss: 0.28938478903040016 accuracy: 0.907035175879397\n",
            "epoch: 66 loss: 0.2884647080504525 accuracy: 0.907035175879397\n",
            "epoch: 67 loss: 0.28756860372634635 accuracy: 0.907035175879397\n",
            "epoch: 68 loss: 0.28669561522056464 accuracy: 0.907035175879397\n",
            "epoch: 69 loss: 0.28584492233872016 accuracy: 0.907035175879397\n",
            "epoch: 70 loss: 0.28501574315635786 accuracy: 0.9095477386934674\n",
            "epoch: 71 loss: 0.2842073318102969 accuracy: 0.9095477386934674\n",
            "epoch: 72 loss: 0.28341897644134767 accuracy: 0.9095477386934674\n",
            "epoch: 73 loss: 0.28264999727642964 accuracy: 0.9095477386934674\n",
            "epoch: 74 loss: 0.2818997448391846 accuracy: 0.907035175879397\n",
            "epoch: 75 loss: 0.2811675982791505 accuracy: 0.907035175879397\n",
            "epoch: 76 loss: 0.28045296381042095 accuracy: 0.907035175879397\n",
            "epoch: 77 loss: 0.2797552732515093 accuracy: 0.907035175879397\n",
            "epoch: 78 loss: 0.2790739826588449 accuracy: 0.907035175879397\n",
            "epoch: 79 loss: 0.2784085710469569 accuracy: 0.907035175879397\n",
            "epoch: 80 loss: 0.2777585391890038 accuracy: 0.907035175879397\n",
            "epoch: 81 loss: 0.2771234084918146 accuracy: 0.907035175879397\n",
            "epoch: 82 loss: 0.2765027199401006 accuracy: 0.907035175879397\n",
            "epoch: 83 loss: 0.2758960331049107 accuracy: 0.907035175879397\n",
            "epoch: 84 loss: 0.2753029252118302 accuracy: 0.907035175879397\n",
            "epoch: 85 loss: 0.27472299026474384 accuracy: 0.907035175879397\n",
            "epoch: 86 loss: 0.2741558382213492 accuracy: 0.907035175879397\n",
            "epoch: 87 loss: 0.2736010942168749 accuracy: 0.907035175879397\n",
            "epoch: 88 loss: 0.27305839783275243 accuracy: 0.907035175879397\n",
            "epoch: 89 loss: 0.27252740240722617 accuracy: 0.907035175879397\n",
            "epoch: 90 loss: 0.27200777438512685 accuracy: 0.907035175879397\n",
            "epoch: 91 loss: 0.2714991927042245 accuracy: 0.907035175879397\n",
            "epoch: 92 loss: 0.27100134821579225 accuracy: 0.9095477386934674\n",
            "epoch: 93 loss: 0.27051394313716765 accuracy: 0.9095477386934674\n",
            "epoch: 94 loss: 0.2700366905342662 accuracy: 0.9095477386934674\n",
            "epoch: 95 loss: 0.2695693138321559 accuracy: 0.9095477386934674\n",
            "epoch: 96 loss: 0.26911154635192425 accuracy: 0.9095477386934674\n",
            "epoch: 97 loss: 0.268663130872215 accuracy: 0.9095477386934674\n",
            "epoch: 98 loss: 0.268223819213897 accuracy: 0.9095477386934674\n",
            "epoch: 99 loss: 0.2677933718464669 accuracy: 0.9095477386934674\n",
            "epoch: 100 loss: 0.26737155751486286 accuracy: 0.9095477386934674\n",
            "epoch: 101 loss: 0.2669581528854606 accuracy: 0.9095477386934674\n",
            "epoch: 102 loss: 0.26655294221011766 accuracy: 0.9095477386934674\n",
            "epoch: 103 loss: 0.2661557170071936 accuracy: 0.9095477386934674\n",
            "epoch: 104 loss: 0.26576627575855494 accuracy: 0.9095477386934674\n",
            "epoch: 105 loss: 0.265384423621637 accuracy: 0.9095477386934674\n",
            "epoch: 106 loss: 0.2650099721556975 accuracy: 0.9095477386934674\n",
            "epoch: 107 loss: 0.26464273906144764 accuracy: 0.9095477386934674\n",
            "epoch: 108 loss: 0.2642825479333059 accuracy: 0.9095477386934674\n",
            "epoch: 109 loss: 0.26392922802356544 accuracy: 0.9095477386934674\n",
            "epoch: 110 loss: 0.26358261401781274 accuracy: 0.9095477386934674\n",
            "epoch: 111 loss: 0.26324254582096707 accuracy: 0.9095477386934674\n",
            "epoch: 112 loss: 0.26290886835337357 accuracy: 0.9095477386934674\n",
            "epoch: 113 loss: 0.2625814313563856 accuracy: 0.9095477386934674\n",
            "epoch: 114 loss: 0.26226008920693933 accuracy: 0.9095477386934674\n",
            "epoch: 115 loss: 0.2619447007406252 accuracy: 0.9095477386934674\n",
            "epoch: 116 loss: 0.2616351290828175 accuracy: 0.9095477386934674\n",
            "epoch: 117 loss: 0.26133124148742587 accuracy: 0.9095477386934674\n",
            "epoch: 118 loss: 0.26103290918287647 accuracy: 0.9095477386934674\n",
            "epoch: 119 loss: 0.2607400072249448 accuracy: 0.9095477386934674\n",
            "epoch: 120 loss: 0.26045241435608396 accuracy: 0.9095477386934674\n",
            "epoch: 121 loss: 0.26017001287092345 accuracy: 0.9095477386934674\n",
            "epoch: 122 loss: 0.2598926884876148 accuracy: 0.9095477386934674\n",
            "epoch: 123 loss: 0.2596203302247365 accuracy: 0.9095477386934674\n",
            "epoch: 124 loss: 0.259352830283479 accuracy: 0.9095477386934674\n",
            "epoch: 125 loss: 0.2590900839348408 accuracy: 0.9095477386934674\n",
            "epoch: 126 loss: 0.25883198941159685 accuracy: 0.9095477386934674\n",
            "epoch: 127 loss: 0.25857844780479855 accuracy: 0.9095477386934674\n",
            "epoch: 128 loss: 0.25832936296458925 accuracy: 0.9095477386934674\n",
            "epoch: 129 loss: 0.2580846414051221 accuracy: 0.9095477386934674\n",
            "epoch: 130 loss: 0.2578441922133896 accuracy: 0.9095477386934674\n",
            "epoch: 131 loss: 0.25760792696176893 accuracy: 0.9095477386934674\n",
            "epoch: 132 loss: 0.2573757596241174 accuracy: 0.9095477386934674\n",
            "epoch: 133 loss: 0.2571476064952454 accuracy: 0.9095477386934674\n",
            "epoch: 134 loss: 0.25692338611360505 accuracy: 0.9095477386934674\n",
            "epoch: 135 loss: 0.2567030191870583 accuracy: 0.9095477386934674\n",
            "epoch: 136 loss: 0.25648642852156656 accuracy: 0.9095477386934674\n",
            "epoch: 137 loss: 0.25627353895267935 accuracy: 0.9095477386934674\n",
            "epoch: 138 loss: 0.25606427727969155 accuracy: 0.9095477386934674\n",
            "epoch: 139 loss: 0.25585857220234637 accuracy: 0.9095477386934674\n",
            "epoch: 140 loss: 0.2556563542599719 accuracy: 0.9095477386934674\n",
            "epoch: 141 loss: 0.2554575557729422 accuracy: 0.9095477386934674\n",
            "epoch: 142 loss: 0.2552621107863604 accuracy: 0.9095477386934674\n",
            "epoch: 143 loss: 0.25506995501586494 accuracy: 0.9095477386934674\n",
            "epoch: 144 loss: 0.25488102579546557 accuracy: 0.9095477386934674\n",
            "epoch: 145 loss: 0.2546952620273226 accuracy: 0.9095477386934674\n",
            "epoch: 146 loss: 0.2545126041333842 accuracy: 0.9095477386934674\n",
            "epoch: 147 loss: 0.2543329940088038 accuracy: 0.9095477386934674\n",
            "epoch: 148 loss: 0.2541563749770551 accuracy: 0.9095477386934674\n",
            "epoch: 149 loss: 0.2539826917466835 accuracy: 0.9095477386934674\n",
            "epoch: 150 loss: 0.25381189036961493 accuracy: 0.9095477386934674\n",
            "epoch: 151 loss: 0.253643918200962 accuracy: 0.9095477386934674\n",
            "epoch: 152 loss: 0.25347872386026454 accuracy: 0.9095477386934674\n",
            "epoch: 153 loss: 0.2533162571941028 accuracy: 0.9095477386934674\n",
            "epoch: 154 loss: 0.25315646924002966 accuracy: 0.9095477386934674\n",
            "epoch: 155 loss: 0.2529993121917665 accuracy: 0.9095477386934674\n",
            "epoch: 156 loss: 0.25284473936561097 accuracy: 0.9095477386934674\n",
            "epoch: 157 loss: 0.2526927051680082 accuracy: 0.9095477386934674\n",
            "epoch: 158 loss: 0.25254316506423974 accuracy: 0.9095477386934674\n",
            "epoch: 159 loss: 0.2523960755481811 accuracy: 0.9095477386934674\n",
            "epoch: 160 loss: 0.2522513941130931 accuracy: 0.9095477386934674\n",
            "epoch: 161 loss: 0.2521090792233979 accuracy: 0.9095477386934674\n",
            "epoch: 162 loss: 0.25196909028740727 accuracy: 0.9095477386934674\n",
            "epoch: 163 loss: 0.25183138763096097 accuracy: 0.9095477386934674\n",
            "epoch: 164 loss: 0.2516959324719456 accuracy: 0.9095477386934674\n",
            "epoch: 165 loss: 0.25156268689565403 accuracy: 0.9095477386934674\n",
            "epoch: 166 loss: 0.2514316138309555 accuracy: 0.9095477386934674\n",
            "epoch: 167 loss: 0.25130267702724807 accuracy: 0.9095477386934674\n",
            "epoch: 168 loss: 0.25117584103215873 accuracy: 0.9095477386934674\n",
            "epoch: 169 loss: 0.2510510711699664 accuracy: 0.9095477386934674\n",
            "epoch: 170 loss: 0.2509283335207192 accuracy: 0.9095477386934674\n",
            "epoch: 171 loss: 0.25080759490002164 accuracy: 0.9095477386934674\n",
            "epoch: 172 loss: 0.25068882283946337 accuracy: 0.9095477386934674\n",
            "epoch: 173 loss: 0.25057198556766913 accuracy: 0.9095477386934674\n",
            "epoch: 174 loss: 0.25045705199194856 accuracy: 0.9095477386934674\n",
            "epoch: 175 loss: 0.2503439916805147 accuracy: 0.9095477386934674\n",
            "epoch: 176 loss: 0.2502327748452642 accuracy: 0.9095477386934674\n",
            "epoch: 177 loss: 0.2501233723250868 accuracy: 0.9095477386934674\n",
            "epoch: 178 loss: 0.250015755569692 accuracy: 0.9095477386934674\n",
            "epoch: 179 loss: 0.24990989662393215 accuracy: 0.9095477386934674\n",
            "epoch: 180 loss: 0.24980576811260347 accuracy: 0.9095477386934674\n",
            "epoch: 181 loss: 0.24970334322571042 accuracy: 0.9095477386934674\n",
            "epoch: 182 loss: 0.24960259570417348 accuracy: 0.9095477386934674\n",
            "epoch: 183 loss: 0.24950349982596962 accuracy: 0.9095477386934674\n",
            "epoch: 184 loss: 0.2494060303926854 accuracy: 0.9095477386934674\n",
            "epoch: 185 loss: 0.24931016271647097 accuracy: 0.9095477386934674\n",
            "epoch: 186 loss: 0.24921587260738118 accuracy: 0.9095477386934674\n",
            "epoch: 187 loss: 0.24912313636109093 accuracy: 0.9095477386934674\n",
            "epoch: 188 loss: 0.24903193074696944 accuracy: 0.9095477386934674\n",
            "epoch: 189 loss: 0.24894223299650012 accuracy: 0.9095477386934674\n",
            "epoch: 190 loss: 0.2488540207920457 accuracy: 0.9095477386934674\n",
            "epoch: 191 loss: 0.24876727225592807 accuracy: 0.907035175879397\n",
            "epoch: 192 loss: 0.24868196593982883 accuracy: 0.907035175879397\n",
            "epoch: 193 loss: 0.24859808081449034 accuracy: 0.907035175879397\n",
            "epoch: 194 loss: 0.2485155962597136 accuracy: 0.907035175879397\n",
            "epoch: 195 loss: 0.24843449205463472 accuracy: 0.907035175879397\n",
            "epoch: 196 loss: 0.24835474836828103 accuracy: 0.907035175879397\n",
            "epoch: 197 loss: 0.2482763457503911 accuracy: 0.907035175879397\n",
            "epoch: 198 loss: 0.24819926512248866 accuracy: 0.907035175879397\n",
            "epoch: 199 loss: 0.24812348776920898 accuracy: 0.907035175879397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJB6xjYF-0_u",
        "outputId": "a905555b-3163-45c0-b378-655f7c556484"
      },
      "source": [
        "print(np.array(theta))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 6.24209117e-03  6.24208872e-03  1.03580223e-02  3.43140315e-02\n",
            "  1.38270707e-02 -2.56901144e+00  4.10092157e-04 -6.82377086e-04\n",
            " -1.65166611e-03 -7.74869218e-04  7.22737669e-04  3.73765200e-04\n",
            " -8.12892052e-04  5.28704039e-03 -9.74059760e-03 -2.64896863e-01\n",
            "  4.13307369e-05 -1.43047081e-04 -2.20651321e-04 -4.67274976e-05\n",
            "  7.25096364e-05  5.85681865e-06  9.06328345e-03  4.13346890e-02\n",
            " -1.93462575e-02 -3.20699485e+00  5.58633511e-04 -2.29480934e-03\n",
            " -3.75886548e-03 -1.07342308e-03  7.63579553e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "ZcTDF2sGNHeK",
        "outputId": "6f4fb1f8-7655-420f-ef4d-812ef74afad6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "number_of_epochs = np.arange(0,num_of_epochs)\n",
        "loss_to_plot = np.array(loss_to_plot)\n",
        "print(number_of_epochs.shape)\n",
        "print(loss_to_plot.shape)\n",
        "plt.plot(number_of_epochs,loss_to_plot)\n"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200,)\n",
            "(200,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4f6e8c76d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "FckHOSFTKe4x",
        "outputId": "dafcbd4a-2ba8-4e5d-9607-8311c9f3a876"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "number_of_epochs = np.arange(0,num_of_epochs)\n",
        "accuracy_to_plot = np.array(accuracy_to_plot)\n",
        "print(number_of_epochs.shape)\n",
        "print(accuracy_to_plot.shape)\n",
        "plt.plot(number_of_epochs,accuracy_to_plot)\n"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200,)\n",
            "(200,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4f6ea864d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWGElEQVR4nO3de4xc53nf8e+zF15EUpRIriiVF5OUKVl0bJjqRpHvdi05ktBIcZMGFGLEQQyrRaIghpMUcl0Igor+oRhNgAJKXRUxkhqOZTmpGyJhLDuJYjVNpIjUnZJJ05QokpbJ5ZKiSIq33Xn6x8wuZ2dmuUNqdmbP7PcDLHbmzMuZh+/M/vbd97znnMhMJEnF19PpAiRJrWGgS1KXMNAlqUsY6JLUJQx0SeoSfZ164WXLluWaNWs69fKSVEjbtm07lJkDjR7rWKCvWbOGrVu3durlJamQImLPZI855SJJXcJAl6QuYaBLUpcw0CWpSxjoktQlDHRJ6hIGuiR1iY6tQ1d3K5WSJ185zJOvDFMqTTxF89VXLOTmDcu5ZM70f/yOnTrLd7cfYM/wiWl/Lc0+11y5iJuuW868/t5OlwIY6HUyk3/YdYjL5s/hp1ZcSkS0/Plf3P8mz+57A6Y4F/3QsdP85Quv8+M3Tk7apq+nhw9cvZQlC+bw9zuGuO6qRXx4/QD9vfV1L5rXz8ffdQVDx07xxO7DTHYu/ASe3nOEv/vBQc6Mli7o/zemVGL831Z34dhL9vZEwxpb7cxIibHfJy1+KzXLjX2W+3qCvgv8LN/3c+9m0w2rW16TgV5l/xsnuW/zdr730gEABhbNZV5/eVZqwZw+bt6wnMMnzvCPPxpmpDR50P2LxfP52LVXsG3PYXYcODbhsVNnSwwdO91UPRFw49ql3HTdcib7uBw7PcL3XjrAidMjfOidy3hh/1Ee2zE06XP29QQjpakvarJ4fj8/++4rWbJgTlO1NvLuFYu5+brlzJ9zbvRSKiVb9xzh8Z1DnL3IXxYXYk5fDx9/1xVsXHVZy385a3YbLSVP7h7mH3YdYrSJn6lq65cvmpaaolNXLBocHMyZcOj/idMjbH7ux3z7mf388yuH6e8NfueT13Lp/H6eevVwebgKvH70FE++Mszcvl4+tH4Zi+Y2/l2YwAv7j7Lr4HGuvHQeP7NuCb3VQRLw02uW8NFrBpjTd/5dGHP7elg0r3/K/8NoKSll0t/bQ6mUHH7rTMN2+46c5Dsv/oSBRXP55IaJQVtr8fx++nvdxSLNNBGxLTMHGz42mwN9257DfP6bz7L38EnWDSzgU+9bwc9vXMGqJZc0bH/kxBnm9vdMOfebmfzkzVNcsWgevT2OCiW1zvkCfdZOuew8cIxNDz3B8kvn8Y3P3ciN65ZM+Sf55U1OP0QEVy2e34oyJalpszbQ/8tfvcz8/l7+4jc+yNKFcztdjiS9bbNykvSxHQf5/s4hfvNfrTfMJXWNWTVCP3V2lK8/+RoPfOcHrF22gF/5wDs6XZIktUzXB/rBN0/xH7/9IodPnGbngeMcPz3CJ951BQ/84nuZ2zczDgaQpFbo+kB/4Ds7eHznEDesXcJt77mSO963gg9cvdQ1yZK6TlcH+ov7j/LnT+/j331kHV+87bpOlyNJ06qrd4r+wfd2cvkl/fz6x9/Z6VIkadp1baCfPDPK/911iE9tXMni+VMfbSlJRde1gf7EK8OcGSnx0WsHOl2KJLVF1wb64zuHmNvXw8+sXdLpUiSpLbo20L+/c4gb1y2dMecplqTp1pWB/uqhE+weOsFHr3G6RdLs0XWBfvTkWX79608zr7+Hmzcs73Q5ktQ2XRfov/ut5/jhwWN85dP/ctLT4EpSN+qqQD95ZpTHdhzkM+9fw8euvaLT5UhSW3VVoG/bc4Szo8kH1y/rdCmS1HZNBXpE3BIROyJiV0Tc0+Dx1RHxWEQ8ExHPR8RtrS91av/4o0P09QQ/vcalipJmnykDPSJ6gQeBW4ENwJ0RsaGm2X8CHsnMjcAm4A9bXWgz/mn3MO9duZiFk1zvU5K6WTMj9BuAXZm5OzPPAA8Dd9S0SeDSyu3FwI9bV2Jzjp8e4fl9R3n/1Uvb/dKSNCM0E+grgL1V9/dVtlW7D/h0ROwDtgC/2eiJIuKuiNgaEVuHhoYuotzJPfXqYUZLyfvXOX8uaXZq1U7RO4E/zsyVwG3A1yKi7rkz86HMHMzMwYGB1h7088yeI/QEbFx9WUufV5KKoplA3w+sqrq/srKt2meBRwAy85+AeUBbh8rP7H2Da5YvYoHz55JmqWYC/SlgfUSsjYg5lHd6bq5p8xrwCYCIuI5yoLd2TuU8SqXkub1vsHH15e16SUmacaYM9MwcAe4GHgVepryaZXtE3B8Rt1ea/TbwuYh4DvgG8KuZmdNVdK1Xhk/w5qkRNq5yukXS7NXU/ERmbqG8s7N6271Vt18CPtja0pr3zGtvAPA+588lzWJdcaTos3uPsHBuH1cPLOx0KZLUMV0R6M/tPcp7Vy6mtyc6XYokdUxXBPreI2+xbmBBp8uQpI4qfKCfHS3xxltnWbZwbqdLkaSOKnygHz5xBsBAlzTrFT7Qh46dBmDZwjkdrkSSOqvwgT7sCF2SgG4I9OPlEfpSA13SLFf4QD80HuhOuUia3Qof6MPHzzCnr4dFnpRL0ixX+EA/dPwMyxbMIcKDiiTNbl0Q6KdZtsj5c0kqfKAPnzjN0gXOn0tS4QP90LEzrnCRJAoe6JnJ8InTrkGXJAoe6G+eGuHsaHqUqCRR8EAfW4PuCF2SCh7ow8fLh/17UJEkFTzQx48SXeAIXZIKHegH3zwFwIDr0CWp2IG+98hJ5vf3ulNUkih4oO8ZfovVSy7xsH9JouCBvvfwW6xackmny5CkGaGwgZ6ZvHa4PEKXJBU40A8dP8PJs6OsXjK/06VI0oxQ2EB/7fBbAKxe6ghdkqDAgb53LNCXLOhwJZI0MxQ20MdG6Csvd8pFkqDggX7lpfOY19/b6VIkaUYobqAPu8JFkqoVNtD3HnmLla5wkaRxhQ3046dHWDy/v9NlSNKMUdhAL5WSXg/5l6RxhQ300Ux6egx0SRrTVKBHxC0RsSMidkXEPZO0+aWIeCkitkfEn7a2zHqlhB5H6JI0rm+qBhHRCzwI3AzsA56KiM2Z+VJVm/XAF4EPZuaRiLhiugoeUyolvYX9+0KSWq+ZSLwB2JWZuzPzDPAwcEdNm88BD2bmEYDMPNjaMuuNpnPoklStmUBfAeytur+vsq3aNcA1EfH/IuKJiLilVQU2kplk4hy6JFWZcsrlAp5nPfAxYCXweES8JzPfqG4UEXcBdwGsXr36ol9stJQAjtAlqUozI/T9wKqq+ysr26rtAzZn5tnMfAXYSTngJ8jMhzJzMDMHBwYGLrZmRrMc6I7QJemcZgL9KWB9RKyNiDnAJmBzTZv/Q3l0TkQsozwFs7uFdU5QKpW/u8pFks6ZMtAzcwS4G3gUeBl4JDO3R8T9EXF7pdmjwHBEvAQ8BvxuZg5PV9GlygjdVS6SdE5Tc+iZuQXYUrPt3qrbCXyh8jXtxqdcHKFL0rhCjnFLYztFnUOXpHGFDPRRA12S6hQz0J1ykaQ6hQz0sVUujtAl6ZxCBvq5EXqHC5GkGaSQgT62U9QpF0k6p5iBnu4UlaRahQx0V7lIUr1CBnrJVS6SVKeQgT7qKhdJqlPQQHeELkm1ChnoJZctSlKdQge6Uy6SdE4hA318ysVAl6RxhQz08RG6c+iSNK6Qge4qF0mqV9BAd5WLJNUqZKC7ykWS6hUy0D30X5LqFTLQx0foBrokjSt0oLvKRZLOKWSgu8pFkuoVNNBd5SJJtQoZ6B76L0n1Chno50boHS5EkmaQQga6q1wkqV6hA91VLpJ0TiED3VUuklSvkIFe8vS5klSnkIE+6pSLJNUpZqCPj9A7XIgkzSCFjMRzZ1t0hC5JYwoZ6ONnWzTQJWlcIQO9kufuFJWkKsUMdM+HLkl1mgr0iLglInZExK6IuOc87X4hIjIiBltXYj1XuUhSvSkDPSJ6gQeBW4ENwJ0RsaFBu0XAbwFPtrrIWq5ykaR6zUTiDcCuzNydmWeAh4E7GrT7z8ADwKkW1tdQyZ2iklSnmUBfAeytur+vsm1cRFwPrMrMvzrfE0XEXRGxNSK2Dg0NXXCxY0ZdtihJdd72pEVE9AC/D/z2VG0z86HMHMzMwYGBgYt+TQ/9l6R6zQT6fmBV1f2VlW1jFgE/Bfx9RLwK3Ahsns4do6V0hYsk1Wom0J8C1kfE2oiYA2wCNo89mJlHM3NZZq7JzDXAE8Dtmbl1WiqmPOXi/LkkTTRloGfmCHA38CjwMvBIZm6PiPsj4vbpLrCRUild4SJJNfqaaZSZW4AtNdvunaTtx95+Wec3WnKELkm1CjnOHc10h6gk1ShkoJdK6ZJFSapRyEAfzXSViyTVKGSgl9KDiiSpVjEDvZT0FrJySZo+hYxFV7lIUr1iBrqrXCSpTiED3VUuklSvkIE+6rlcJKlOIQO9PELvdBWSNLMUM9Bdhy5JdQoZ6KPOoUtSnUIGuiN0SapXyEAfLRnoklSrmIGeEE65SNIEhQz0UinpNc8laYJCBrpTLpJUr5iBnq5ykaRahQz0dJWLJNUpZKA75SJJ9YoZ6F7gQpLqFDLQPZeLJNUrZKA75SJJ9QoZ6CVXuUhSnUIGuiN0SapXyEAveQk6SapT0EDHi0RLUo1CBrpTLpJUr7CB7gBdkiYqZKCXMp1ykaQahQx0p1wkqV4hA91VLpJUr6CB7ioXSapVyEB3ykWS6jUV6BFxS0TsiIhdEXFPg8e/EBEvRcTzEfG3EfGO1pd6TslVLpJUZ8pAj4he4EHgVmADcGdEbKhp9gwwmJnvBf4M+L1WF1pt1FUuklSnmRH6DcCuzNydmWeAh4E7qhtk5mOZ+Vbl7hPAytaWOZFTLpJUr5lAXwHsrbq/r7JtMp8F/rrRAxFxV0RsjYitQ0NDzVdZw1UuklSvpTtFI+LTwCDw5UaPZ+ZDmTmYmYMDAwMX/TqjJadcJKlWXxNt9gOrqu6vrGybICJuAr4EfDQzT7emvMZKiSN0SarRzAj9KWB9RKyNiDnAJmBzdYOI2Aj8D+D2zDzY+jLPKZUScB26JNWaMtAzcwS4G3gUeBl4JDO3R8T9EXF7pdmXgYXAtyLi2YjYPMnTvW2jWQ50B+iSNFEzUy5k5hZgS822e6tu39TiuiY1WhmhO+UiSRMV7kjRUmWE7rJFSZqocIE+6hy6JDVUuEAvlcrfnXKRpImKF+hjUy7muSRNULhAH3UOXZIaKlygj61DD+fQJWmCwgW6I3RJaqx4ge4qF0lqqHCB7ioXSWqscIF+bsqlw4VI0gxTuFgsjZ/LxRG6JFUrXqCX3CkqSY0ULtBHHaFLUkPFC/SSgS5JjRQu0MdWuTjlIkkTFS7QXeUiSY0VLhadcpGkxgoX6Omh/5LUUOEC3UP/Jamx4gV6erZFSWqkcIHuKhdJaqxwge4qF0lqrHCxWHKViyQ1VLhAH/VcLpLUUOEC3bMtSlJjBrokdYnCBfqoq1wkqaHiBbqrXCSpocLFoqtcJKmxwgW6q1wkqbHiBbo7RSWpocIFumdblKTGChfoY6tcHKFL0kTFC/SxKZfCVS5J06twsVjyfOiS1FBTgR4Rt0TEjojYFRH3NHh8bkR8s/L4kxGxptWFjnGViyQ1NmWgR0Qv8CBwK7ABuDMiNtQ0+yxwJDPfCfwB8ECrCx0zfui/gS5JEzQzQr8B2JWZuzPzDPAwcEdNmzuAP6nc/jPgEzFNlxTyEnSS1Fgzgb4C2Ft1f19lW8M2mTkCHAWW1j5RRNwVEVsjYuvQ0NBFFbxuYCG3vedK+noNdEmq1tfOF8vMh4CHAAYHB/NinuPmDcu5ecPyltYlSd2gmRH6fmBV1f2VlW0N20REH7AYGG5FgZKk5jQT6E8B6yNibUTMATYBm2vabAY+U7n9i8Df5dghnZKktphyyiUzRyLibuBRoBf4amZuj4j7ga2ZuRn4I+BrEbELOEw59CVJbdTUHHpmbgG21Gy7t+r2KeDftrY0SdKFKNyRopKkxgx0SeoSBrokdQkDXZK6RHRqdWFEDAF7LvKfLwMOtbCcVpqptVnXhbGuCzdTa+u2ut6RmQONHuhYoL8dEbE1Mwc7XUcjM7U267ow1nXhZmpts6kup1wkqUsY6JLUJYoa6A91uoDzmKm1WdeFsa4LN1NrmzV1FXIOXZJUr6gjdElSDQNdkrpE4QJ9qgtWt7GOVRHxWES8FBHbI+K3Ktvvi4j9EfFs5eu2DtT2akS8UHn9rZVtSyLiexHxw8r3y9tc07VVffJsRLwZEZ/vVH9FxFcj4mBEvFi1rWEfRdl/q3zmno+I69tc15cj4geV1/52RFxW2b4mIk5W9d1X2lzXpO9dRHyx0l87IuJnp6uu89T2zaq6Xo2IZyvb29Jn58mH6f2MZWZhviifvvdHwDpgDvAcsKFDtVwFXF+5vQjYSfki2vcBv9PhfnoVWFaz7feAeyq37wEe6PD7+BPgHZ3qL+AjwPXAi1P1EXAb8NdAADcCT7a5rk8CfZXbD1TVtaa6XQf6q+F7V/k5eA6YC6yt/Mz2trO2msf/K3BvO/vsPPkwrZ+xoo3Qm7lgdVtk5uuZ+XTl9jHgZeqvtTqTVF/I+0+An+9gLZ8AfpSZF3uk8NuWmY9TPnd/tcn66A7gf2XZE8BlEXFVu+rKzO9m+Vq9AE9QvmpYW03SX5O5A3g4M09n5ivALso/u22vLSIC+CXgG9P1+pPUNFk+TOtnrGiB3swFq9suItYAG4EnK5vurvzZ9NV2T21UJPDdiNgWEXdVti3PzNcrt38CdPLCrJuY+APW6f4aM1kfzaTP3a9RHsmNWRsRz0TE9yPiwx2op9F7N5P668PAgcz8YdW2tvZZTT5M62esaIE+40TEQuDPgc9n5pvAfweuBt4HvE75z712+1BmXg/cCvxGRHyk+sEs/43XkfWqUb6M4e3AtyqbZkJ/1elkH00mIr4EjABfr2x6HVidmRuBLwB/GhGXtrGkGfne1biTiYOHtvZZg3wYNx2fsaIFejMXrG6biOin/GZ9PTP/N0BmHsjM0cwsAf+TafxTczKZub/y/SDw7UoNB8b+hKt8P9juuipuBZ7OzAOVGjveX1Um66OOf+4i4leBfw38ciUIqExpDFdub6M8V31Nu2o6z3vX8f6C8QvW/xvgm2Pb2tlnjfKBaf6MFS3Qm7lgdVtU5ub+CHg5M3+/anv1vNengBdr/+0017UgIhaN3aa8Q+1FJl7I+zPAX7SzrioTRkyd7q8ak/XRZuBXKisRbgSOVv3ZPO0i4hbgPwC3Z+ZbVdsHIqK3cnsdsB7Y3ca6JnvvNgObImJuRKyt1PXP7aqryk3ADzJz39iGdvXZZPnAdH/Gpntvb6u/KO8N3kn5N+uXOljHhyj/ufQ88Gzl6zbga8ALle2bgavaXNc6yisMngO2j/URsBT4W+CHwN8ASzrQZwuAYWBx1baO9BflXyqvA2cpz1d+drI+orzy4MHKZ+4FYLDNde2iPL869jn7SqXtL1Te42eBp4Gfa3Ndk753wJcq/bUDuLXd72Vl+x8D/76mbVv67Dz5MK2fMQ/9l6QuUbQpF0nSJAx0SeoSBrokdQkDXZK6hIEuSV3CQJekLmGgS1KX+P9jeCj/0xRqbAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMQVVqqNFKBB",
        "outputId": "0bbdb44d-0e5e-4894-8adf-c1ed1a126840"
      },
      "source": [
        "y_pred_train_lor = predict(x_training,theta)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_train_lor)):\n",
        "  if y_pred_train_lor[i] == y_train[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "361\n",
            "37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6LijayPLIaX",
        "outputId": "763672f5-6e6e-48db-cc51-404aef509f3c"
      },
      "source": [
        "y_pred_test_lor = predict(x_testing,theta)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_test_lor)):\n",
        "  if y_pred_test_lor[i] == y_test[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFRlDuv9JLNj"
      },
      "source": [
        "y_pred_train_acc_lor = []\n",
        "y_train_acc_lor = []\n",
        "for i in range(len(y_pred_train_lor)):\n",
        "\n",
        "  if y_pred_train_lor[i] == -1:\n",
        "    y_pred_train_acc_lor.append(-1)\n",
        "  if y_pred_train_lor[i] == 1:\n",
        "    y_pred_train_acc_lor.append(1)\n",
        "\n",
        "  if y_train[i] == -1:\n",
        "    y_train_acc_lor.append(-1)\n",
        "  \n",
        "  if y_train[i] == 1:\n",
        "    y_train_acc_lor.append(1)\n",
        "\n",
        "y_pred_train_acc_lor = np.array(y_pred_train_acc_lor)\n",
        "y_train_acc_lor = np.array(y_train_acc_lor)\n",
        "# print(y_pred_train_acc_lor)\n",
        "# print(y_train_acc_lor)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWGe6HjUDajy",
        "outputId": "2c9f2dbe-be2d-440e-ff9e-4a496a453fd2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train_acc_lor, y_pred = y_pred_train_acc_lor))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train_acc_lor, y_pred_train_acc_lor).ravel()\n",
        "training_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lor:\",training_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train_acc_lor, y_pred = y_pred_train_acc_lor))\n",
        "\n"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[121  28]\n",
            " [  9 240]]\n",
            "121 28 9 240\n",
            "training accuracy_lor: 90.7035175879397 %\n",
            "0.907035175879397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERTj_acGEXMo"
      },
      "source": [
        "y_pred_test_acc_lor = []\n",
        "y_test_acc_lor = []\n",
        "for i in range(len(y_pred_test_lor)):\n",
        "\n",
        "  if y_pred_test_lor[i] == -1:\n",
        "    y_pred_test_acc_lor.append(-1)\n",
        "  if y_pred_test_lor[i] == 1:\n",
        "    y_pred_test_acc_lor.append(1)\n",
        "\n",
        "  if y_test[i] == -1:\n",
        "    y_test_acc_lor.append(-1)\n",
        "  \n",
        "  if y_test[i] == 1:\n",
        "    y_test_acc_lor.append(1)\n",
        "\n",
        "y_pred_test_acc_lor = np.array(y_pred_test_acc_lor)\n",
        "y_test_acc_lor = np.array(y_test_acc_lor)\n",
        "# print(y_pred_test_acc_lor)\n",
        "# print(y_test_acc_lor)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnYRXwalEn5Z",
        "outputId": "8dc3f8fb-c155-4918-e929-7f32f09aff64"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test_acc_lor, y_pred = y_pred_test_acc_lor))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test_acc_lor, y_pred_test_acc_lor).ravel()\n",
        "testing_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lor:\",testing_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test_acc_lor, y_pred = y_pred_test_acc_lor))\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[ 57   6]\n",
            " [  3 105]]\n",
            "57 6 3 105\n",
            "testing accuracy_lor: 94.73684210526315 %\n",
            "0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8o9PiLRaGy7"
      },
      "source": [
        "# sklearn logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aqrGk9xoppj",
        "outputId": "223484c8-e4b9-45f4-eeb1-4008e573c7cc"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression().fit(x_train, y_train)  "
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8RI6JERpVPD",
        "outputId": "64e92091-d99a-403f-9428-eb1c2a503054"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train, y_pred = clf.predict(x_train)))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train, clf.predict(x_train)).ravel()\n",
        "training_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lor:\",training_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train, y_pred = clf.predict(x_train)))\n"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[135  14]\n",
            " [ 10 239]]\n",
            "135 14 10 239\n",
            "training accuracy_lor: 93.96984924623115 %\n",
            "0.9396984924623115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keI_Rg3Sp57R",
        "outputId": "b9355b60-066b-4d50-bf9b-6971a6c8d10b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test, y_pred = clf.predict(x_test)))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test, clf.predict(x_test)).ravel()\n",
        "testing_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lor:\",testing_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test, y_pred = clf.predict(x_test)))"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[ 59   4]\n",
            " [  1 107]]\n",
            "59 4 1 107\n",
            "testing accuracy_lor: 97.07602339181285 %\n",
            "0.9707602339181286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "equTWLghyQbN"
      },
      "source": [
        "## **80:20 (train:test) split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L_7CrugywQg",
        "outputId": "b7221767-dbb5-48f7-94ec-abdc3eed1963"
      },
      "source": [
        "print(X1.shape)\n",
        "print(Y1.shape)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPdTFrd5mITL"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X1,Y1,test_size = 0.2,shuffle = True,random_state = 42)"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2Een3v4yzDA",
        "outputId": "13a9c7b9-1e33-433a-e6af-21e3030dcbfb"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(455, 30)\n",
            "(114, 30)\n",
            "(455,)\n",
            "(114,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahQKWTHXzRbY"
      },
      "source": [
        "# Data Preprocessing for Half-Space Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pllb7Tq5zSrC",
        "outputId": "9e7a2094-81fa-4cc3-fc58-eb53e1b3f932"
      },
      "source": [
        "X_Malign = []\n",
        "X_Benign = []\n",
        "Y_Malign = []\n",
        "Y_Benign = []\n",
        "\n",
        "for i in range(len(x_train)):\n",
        "\n",
        "  if y_train[i] == -1:\n",
        "    X_Malign.append(x_train[i])\n",
        "    Y_Malign.append(y_train[i])\n",
        "    \n",
        "  elif y_train[i] == 1:\n",
        "    X_Benign.append(x_train[i])\n",
        "    Y_Benign.append(y_train[i])\n",
        "\n",
        "X_Malign = np.array(X_Malign)\n",
        "X_Benign = np.array(X_Benign)\n",
        "\n",
        "print(X_Malign.shape)\n",
        "print(X_Benign.shape)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(169, 30)\n",
            "(286, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dNEsUSPzZQx",
        "outputId": "f1f50ee1-7911-4686-dc99-d50b77f060c3"
      },
      "source": [
        "def euclidean_distance(x1,c_):\n",
        "  \n",
        "  dist = np.sqrt(np.sum((x1-c_)**2))\n",
        "\n",
        "  return dist\n",
        "\n",
        "# centroidd of Malign data\n",
        "X_Malign_Centroid = X_Malign.mean(axis = 0)\n",
        "X_Benign_Centroid = X_Benign.mean(axis = 0)\n",
        "\n",
        "distance_Benign = []\n",
        "distance_Malign = []\n",
        "\n",
        "X_redundant_points = []\n",
        "Y_redundant_points = []\n",
        "\n",
        "X_sep= []\n",
        "Y_sep = []\n",
        "\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "\n",
        "  dist_Malign = euclidean_distance(x_train[i],X_Malign_Centroid) \n",
        "  dist_Benign = euclidean_distance(x_train[i],X_Benign_Centroid) \n",
        "\n",
        "  if y_train[i] == -1 and dist_Malign < dist_Benign and dist_Malign <= 1000: # -1:M, 1:B # correct\n",
        "\n",
        "    # X_Malign_sep.append(x_train[i])\n",
        "    # Y_Malign.append(y_train[i])\n",
        "    X_sep.append(x_train[i])\n",
        "    Y_sep.append(y_train[i])\n",
        "    distance_Malign.append(dist_Malign)\n",
        "  \n",
        "  elif y_train[i] == -1 and dist_Malign > dist_Benign: # incorrect\n",
        "    \n",
        "    X_redundant_points.append(x_train[i])\n",
        "    Y_redundant_points.append(y_train[i])\n",
        "\n",
        "\n",
        "  elif y_train[i] == 1 and dist_Benign < dist_Malign and dist_Benign <= 200  : # -1:M, 1:B # correct\n",
        "\n",
        "    # X_Malign_sep.append(x_train[i])\n",
        "    # Y_Malign.append(y_train[i])\n",
        "    X_sep.append(x_train[i])\n",
        "    Y_sep.append(y_train[i])\n",
        "    distance_Benign.append(dist_Benign)\n",
        "  \n",
        "  elif y_train[i] == 1 and dist_Benign > dist_Malign: # incorrect\n",
        "    \n",
        "    X_redundant_points.append(x_train[i])\n",
        "    Y_redundant_points.append(y_train[i])\n",
        "\n",
        "X_sep = np.array(X_sep)\n",
        "Y_sep = np.array(Y_sep)\n",
        "\n",
        "print(X_sep.shape)\n",
        "print(Y_sep.shape)\n",
        "\n",
        "  "
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(288, 30)\n",
            "(288,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGPdNjhiz1OC"
      },
      "source": [
        "\n",
        "**PCA on Linearly Seperable Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "tFUVaSe6zfKe",
        "outputId": "2d215ec6-e32a-46fc-ac14-f8ee5511af1e"
      },
      "source": [
        "# PCA on Linearly Seperable Dataset\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(X_sep)\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
        "Y_df = pd.DataFrame(Y_sep,columns=['target'])\n",
        "finalDf = pd.concat([principalDf, Y_df[['target']]], axis = 1)\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('2 component PCA', fontsize = 20)\n",
        "targets = [1,-1]\n",
        "colors = ['r', 'g']\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['target'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1'], finalDf.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnMNnkpJ2bao"
      },
      "source": [
        "# LP Solver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCZ6JcKyzknM",
        "outputId": "46947685-5c3b-4409-8791-dd847eaec820"
      },
      "source": [
        "from scipy.optimize import linprog\n",
        "A = []\n",
        "for i in range(len(X_sep)):\n",
        "  A.append(X_sep[i]*Y_sep[i]) \n",
        "A = -1*np.array(A)\n",
        "print(A.shape)\n",
        "\n",
        "V = -1*np.ones(len(Y_sep))\n",
        "V = np.reshape(V,(len(V),1))\n",
        "print(V.shape)\n",
        "\n",
        "\n",
        "obj = [0 for j in range(np.array(X_sep).shape[1])]\n",
        "\n",
        "lhs_ineq = []\n",
        "rhs_ineq = []\n",
        "\n",
        "for i in range(len(A)):\n",
        "  lhs_ineq.append(list(A[i]))\n",
        "  rhs_ineq.append(V[i])\n",
        "bnd=(None,None)\n",
        "opt = linprog(c=obj,A_ub=lhs_ineq,b_ub=rhs_ineq,bounds=bnd,method ='simplex',options={\"disp\": True})\n",
        "\n",
        "\n",
        "print(opt)\n",
        "weights = opt['x']\n",
        "print(weights.shape)\n",
        "\n",
        "optimized_weights = []\n",
        "for i in weights:\n",
        "  optimized_weights.append(i)\n",
        "optimized_weights = np.array(optimized_weights)\n",
        "\n",
        "y_pred_train_lp = np.sign(np.matmul(X_sep,optimized_weights))\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_train_lp)):\n",
        "  if y_pred_train_lp[i] == Y_sep[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "y_pred_train_acc_lp = []\n",
        "y_train_acc_lp = []\n",
        "for i in range(len(y_pred_train_lp)):\n",
        "\n",
        "  if y_pred_train_lp[i] == -1:\n",
        "    y_pred_train_acc_lp.append(-1)\n",
        "  if y_pred_train_lp[i] == 1:\n",
        "    y_pred_train_acc_lp.append(1)\n",
        "\n",
        "  if Y_sep[i] == -1:\n",
        "    y_train_acc_lp.append(-1)\n",
        "  \n",
        "  if Y_sep[i] == 1:\n",
        "    y_train_acc_lp.append(1)\n",
        "\n",
        "y_pred_train_acc_lp = np.array(y_pred_train_acc_lp)\n",
        "y_train_acc_lp = np.array(y_train_acc_lp)\n",
        "# print(y_pred_train_acc_lp)\n",
        "# print(y_train_acc_lp)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train_acc_lp, y_pred_train_acc_lp).ravel()\n",
        "training_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lp:\",training_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "\n",
        "\n",
        "y_pred_test_lp = np.sign(np.matmul(x_test,optimized_weights))\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "  if y_pred_test_lp[i] == y_test[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "\n",
        "y_pred_test_acc_lp = []\n",
        "y_test_acc_lp = []\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "\n",
        "  if y_pred_test_lp[i] == -1:\n",
        "    y_pred_test_acc_lp.append(-1)\n",
        "  if y_pred_test_lp[i] == 1:\n",
        "    y_pred_test_acc_lp.append(1)\n",
        "\n",
        "  if y_test[i] == -1:\n",
        "    y_test_acc_lp.append(-1)\n",
        "  \n",
        "  if y_test[i] == 1:\n",
        "    y_test_acc_lp.append(1)\n",
        "\n",
        "y_pred_test_acc_lp = np.array(y_pred_test_acc_lp)\n",
        "y_test_acc_lp = np.array(y_test_acc_lp)\n",
        "# print(y_pred_test_acc_lp)\n",
        "# print(y_test_acc_lp)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test_acc_lp, y_pred_test_acc_lp).ravel()\n",
        "testing_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lp:\",testing_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "\n"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(288, 30)\n",
            "(288, 1)\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.000000    \n",
            "         Iterations: 493\n",
            "     con: array([], dtype=float64)\n",
            "     fun: 0.0\n",
            " message: 'Optimization terminated successfully.'\n",
            "     nit: 493\n",
            "   slack: array([ 1.75716875e+01,  3.02820093e+00,  5.21666083e+00,  3.53688914e+00,\n",
            "        1.11547355e+01,  4.14772516e+00,  1.39025980e+01,  3.62349345e+00,\n",
            "        2.50040172e+00,  1.01630674e+01, -8.45545856e-13,  5.59440503e+00,\n",
            "        6.21724894e-13,  4.09721805e+00,  2.84751090e+00,  6.27314321e+00,\n",
            "        5.72664743e+00,  7.17960070e+00,  4.07616627e+00,  3.23760106e+00,\n",
            "       -7.49622586e-13,  9.21707249e+00,  1.99972140e+00,  8.58700064e+00,\n",
            "        1.21535721e+01,  8.16814309e+00,  6.89763452e+00,  8.12034764e+00,\n",
            "        7.00091948e+00,  6.04850647e+00,  7.25571992e+00,  2.26731305e+00,\n",
            "        5.51812138e+00,  2.03432447e+00,  4.75020770e+00,  3.32315542e+00,\n",
            "        5.32907052e-13,  2.86890728e+00,  9.69553254e+00,  3.37796984e+00,\n",
            "        3.75752802e+00,  2.03560970e+00,  5.29117347e+00,  2.42511279e+00,\n",
            "        7.24759083e+00,  1.05144954e+01,  7.35074120e+00,  4.85439568e+00,\n",
            "        8.66569973e-01,  7.91266236e+00,  4.34387594e+00, -8.59756710e-13,\n",
            "        4.27612077e+00,  7.23526708e+00,  8.71876266e+00,  7.92095706e+00,\n",
            "        3.33928526e+00,  1.61046688e+00,  7.30837796e+00,  9.12105673e+00,\n",
            "        5.33946503e+00,  9.62672659e+00,  6.29219096e+00,  9.64741200e+00,\n",
            "       -6.57252031e-13,  9.90949386e+00,  3.52331948e+00,  5.10669668e+00,\n",
            "        9.26507650e+00,  3.02159306e+00,  2.90576436e+00,  8.08006171e+00,\n",
            "        4.25640389e+00,  1.16435180e+00,  2.04266446e+00,  3.96426376e+00,\n",
            "        1.62420061e+00,  1.07129553e+01,  1.03704132e+01,  1.38089727e+00,\n",
            "        1.81635299e+00,  5.27783093e+00,  1.30344573e+00,  2.33584551e+00,\n",
            "        9.21941794e+00,  2.34418203e+00,  1.23130377e+00,  8.25635997e+00,\n",
            "        6.82234152e+00,  7.92206821e+00,  2.07425637e+00,  5.45982325e+00,\n",
            "        4.59953389e+00,  2.22694882e+00,  7.40321766e+00,  9.52584642e+00,\n",
            "        5.93047840e+00,  5.73531952e+00,  8.00934461e+00,  1.28718948e+01,\n",
            "        4.66024068e+00,  6.06179844e+00,  1.32759779e+00,  7.90309193e-01,\n",
            "        3.06658430e+00,  6.42762630e+00,  3.92203004e+00,  5.47158036e+00,\n",
            "        1.53947557e+00,  7.51558466e+00,  7.81255642e+00,  9.11261158e+00,\n",
            "        5.91626103e+00,  5.45599374e+00,  1.70245899e+01,  8.01441076e+00,\n",
            "        3.33619426e+00,  7.14607136e+00,  2.61060917e+00,  5.12418031e+00,\n",
            "        6.23749696e+00,  7.90236261e+00,  2.84993597e+00,  5.92689899e+00,\n",
            "        5.84733630e+00,  5.54067889e+00,  8.82264734e+00,  2.92560789e+00,\n",
            "        1.03497522e+01,  1.50688475e+01,  6.13092951e+00,  1.57377869e+01,\n",
            "        3.76450088e+00,  1.56895760e+01,  5.31623659e+00,  2.87622504e+01,\n",
            "        1.37289616e+01,  1.28924086e+00,  1.12030622e+01,  1.43306662e+01,\n",
            "        1.14011113e+01,  7.63951549e+00,  8.81830272e+00,  6.84019982e+00,\n",
            "        1.01505523e+01,  1.31975774e+01,  1.19379996e+01,  2.86217199e+00,\n",
            "        9.46705912e+00,  4.43714565e+00,  5.30418263e+00,  5.64250290e+00,\n",
            "        5.02800064e+00,  1.11362312e+01,  1.32491229e+01,  6.36105291e+00,\n",
            "        2.40208583e+00,  8.26643656e+00,  1.17787810e+01,  3.52505233e+00,\n",
            "        3.74575110e+00,  7.19186034e+00,  6.63762864e+00,  3.41606638e+00,\n",
            "        4.11817741e+00,  7.36679775e+00,  4.40691402e+00,  3.76270656e+00,\n",
            "        6.82206526e+00,  4.01038951e+00,  4.76726422e+00,  4.98794684e+00,\n",
            "        4.03798149e+00,  6.07774815e+00,  3.55377296e+00,  4.62675341e+00,\n",
            "        1.63542797e+01,  5.72249803e+00,  8.84573975e+00,  5.41677880e+00,\n",
            "        6.14273260e+00,  6.74480954e+00, -8.73967565e-13,  4.70737343e+00,\n",
            "       -7.63833441e-13,  5.24037969e+00,  3.69916889e+00,  4.77516753e+00,\n",
            "        6.52888867e+00,  3.16594600e+00,  5.06094100e+00,  1.48654469e+01,\n",
            "        4.03302432e+00,  3.25695237e+00,  4.88093076e+00,  2.36008200e+00,\n",
            "        3.17046852e+00,  1.70395835e+01,  6.02305615e+00,  9.36593076e+00,\n",
            "        1.85478598e+00,  1.47609697e+01,  9.62278352e+00,  4.82220082e+00,\n",
            "        2.44143660e+00,  2.47917876e+00,  3.34456989e+00,  4.41187335e+00,\n",
            "        8.08419406e+00, -7.17648163e-13,  5.69297399e+00,  6.54765108e+00,\n",
            "        1.53874921e+00,  8.34173296e+00,  8.47159595e+00,  5.47224221e+00,\n",
            "        5.93682258e+00,  1.26740875e+01,  3.45001459e+00,  7.14946298e+00,\n",
            "        5.52719116e+00,  1.16363277e+01,  1.15199567e+01,  4.19806789e+00,\n",
            "        6.71266048e+00,  1.12598669e+01,  6.65261856e+00,  6.84845778e+00,\n",
            "        8.04053287e+00,  2.29792342e+00,  1.19827744e+00,  2.80130576e+00,\n",
            "        7.00736732e+00,  7.24996392e+00,  7.72433879e+00,  6.46415589e-01,\n",
            "        4.01448165e+00,  3.49109326e+00,  7.44607851e+00,  3.56612007e+00,\n",
            "        8.71635794e-01, -8.20676860e-13,  6.86343351e+00,  7.00802150e+00,\n",
            "        2.87341708e+00,  4.95060587e+00,  5.00706422e+00,  7.27371445e+00,\n",
            "        1.54868115e+00,  5.68917797e+00,  8.01041217e+00,  6.13288518e+00,\n",
            "        1.10948136e+01,  4.45963556e+00,  1.95185695e+00,  3.89344892e-01,\n",
            "        8.43340086e+00,  4.72855798e+00,  2.41170674e+00,  1.12481455e+01,\n",
            "        5.61980500e+00,  5.79012695e+00,  7.05225439e+00,  6.34487073e+00,\n",
            "        4.05448001e+00,  4.89475314e+00,  6.01381589e+00,  3.42831443e+00,\n",
            "        4.52089181e+00,  7.38222932e+00,  6.84882232e+00,  1.75368354e+01,\n",
            "        7.65472593e+00,  8.91465846e+00,  7.10478951e+00,  1.17900238e+01,\n",
            "        8.91827411e+00,  3.81778559e+00,  6.86008486e+00,  1.94405228e+01,\n",
            "        1.34642918e+01,  4.09348118e+00,  4.34986383e+00,  3.35377201e+00,\n",
            "        5.23830586e+00,  4.12789617e-01,  3.03372729e+00,  2.68913663e+00])\n",
            "  status: 0\n",
            " success: True\n",
            "       x: array([22.76430564,  0.38695641, -2.1418551 , -0.09914183,  0.        ,\n",
            "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
            "        0.        ,  0.        ,  3.41639849, -0.15021881,  0.        ,\n",
            "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
            "       -9.6564575 , -0.33223975,  0.43714721,  0.05525293,  0.        ,\n",
            "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])\n",
            "(30,)\n",
            "288\n",
            "0\n",
            "confusion_matrix:\n",
            " [[104   0]\n",
            " [  0 184]]\n",
            "104 0 0 184\n",
            "training accuracy_lp: 100.0 %\n",
            "1.0\n",
            "105\n",
            "9\n",
            "confusion_matrix:\n",
            " [[39  4]\n",
            " [ 5 66]]\n",
            "39 4 5 66\n",
            "testing accuracy_lp: 92.10526315789474 %\n",
            "0.9210526315789473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upOriNeH17dy"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atae1S9i0Ow2",
        "outputId": "da7bb4f3-cc4c-4a37-edbd-c5cbc507daed"
      },
      "source": [
        "def perceptron(x_train,y_train):\n",
        "\n",
        "  weights = np.zeros(x_train.shape[1])\n",
        "  \n",
        "  flag = 0\n",
        "  t = 0\n",
        "  while(flag == 0):\n",
        "  # for t in range(num_iterations):\n",
        "    flag = 1\n",
        "    for i in range(len(x_train)):\n",
        "      if y_train[i]*np.sum(x_train[i]*weights) <= 0:\n",
        "        flag = 0\n",
        "        weights = weights + y_train[i]*x_train[i]\n",
        "    # print(weights)\n",
        "    t+=1\n",
        "\n",
        "  return weights,t\n",
        "  \n",
        "w,t = perceptron(X_sep,Y_sep)\n",
        "print(w,t)\n",
        "\n",
        "print(\"weights:\\n\",w,\"\\n num_of_iterations:\",t)\n",
        "\n",
        "y_pred_train_per = np.sign(np.matmul(X_sep,w))\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_train_per)):\n",
        "  if y_pred_train_per[i] == Y_sep[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "y_pred_train_acc_lp = []\n",
        "y_train_acc_lp = []\n",
        "for i in range(len(y_pred_train_lp)):\n",
        "\n",
        "  if y_pred_train_lp[i] == -1:\n",
        "    y_pred_train_acc_lp.append(-1)\n",
        "  if y_pred_train_lp[i] == 1:\n",
        "    y_pred_train_acc_lp.append(1)\n",
        "\n",
        "  if Y_sep[i] == -1:\n",
        "    y_train_acc_lp.append(-1)\n",
        "  \n",
        "  if Y_sep[i] == 1:\n",
        "    y_train_acc_lp.append(1)\n",
        "\n",
        "y_pred_train_acc_lp = np.array(y_pred_train_acc_lp)\n",
        "y_train_acc_lp = np.array(y_train_acc_lp)\n",
        "# print(y_pred_train_acc_lp)\n",
        "# print(y_train_acc_lp)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train_acc_lp, y_pred_train_acc_lp).ravel()\n",
        "training_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lp:\",training_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "\n",
        "\n",
        "y_pred_test_lp = np.sign(np.matmul(x_test,w))\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "  if y_pred_test_lp[i] == y_test[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "y_pred_test_acc_lp = []\n",
        "y_test_acc_lp = []\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "\n",
        "  if y_pred_test_lp[i] == -1:\n",
        "    y_pred_test_acc_lp.append(-1)\n",
        "  if y_pred_test_lp[i] == 1:\n",
        "    y_pred_test_acc_lp.append(1)\n",
        "\n",
        "  if y_test[i] == -1:\n",
        "    y_test_acc_lp.append(-1)\n",
        "  \n",
        "  if y_test[i] == 1:\n",
        "    y_test_acc_lp.append(1)\n",
        "\n",
        "y_pred_test_acc_lp = np.array(y_pred_test_acc_lp)\n",
        "y_test_acc_lp = np.array(y_test_acc_lp)\n",
        "# print(y_pred_test_acc_lp)\n",
        "# print(y_test_acc_lp)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test_acc_lp, y_pred_test_acc_lp).ravel()\n",
        "testing_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lp:\",testing_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "\n",
        "\n"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.7669500e+03  2.8029100e+03  1.0660270e+04  9.2990000e+02\n",
            "  1.9988970e+01  5.5589000e+00 -1.7597314e+01 -6.6236550e+00\n",
            "  3.5897900e+01  1.4954450e+01  2.3993700e+01  1.8341950e+02\n",
            "  1.1014760e+02 -1.6793080e+03  4.6381600e-01 -1.1688000e-01\n",
            " -3.0194281e+00 -2.2792100e-01  3.6289640e+00  2.8677140e-01\n",
            "  1.9172000e+03  3.9067600e+03  1.1475540e+04 -3.7137000e+03\n",
            "  2.6951890e+01  1.3029570e+01 -1.6176480e+01 -1.5859380e+00\n",
            "  5.7381300e+01  1.8152540e+01] 34\n",
            "weights:\n",
            " [ 1.7669500e+03  2.8029100e+03  1.0660270e+04  9.2990000e+02\n",
            "  1.9988970e+01  5.5589000e+00 -1.7597314e+01 -6.6236550e+00\n",
            "  3.5897900e+01  1.4954450e+01  2.3993700e+01  1.8341950e+02\n",
            "  1.1014760e+02 -1.6793080e+03  4.6381600e-01 -1.1688000e-01\n",
            " -3.0194281e+00 -2.2792100e-01  3.6289640e+00  2.8677140e-01\n",
            "  1.9172000e+03  3.9067600e+03  1.1475540e+04 -3.7137000e+03\n",
            "  2.6951890e+01  1.3029570e+01 -1.6176480e+01 -1.5859380e+00\n",
            "  5.7381300e+01  1.8152540e+01] \n",
            " num_of_iterations: 34\n",
            "288\n",
            "0\n",
            "confusion_matrix:\n",
            " [[104   0]\n",
            " [  0 184]]\n",
            "104 0 0 184\n",
            "training accuracy_lp: 100.0 %\n",
            "1.0\n",
            "108\n",
            "6\n",
            "confusion_matrix:\n",
            " [[40  3]\n",
            " [ 3 68]]\n",
            "40 3 3 68\n",
            "testing accuracy_lp: 94.73684210526315 %\n",
            "0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJIvN2ZG2EPz"
      },
      "source": [
        "# Logistic Regression Classifier (Scratch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y-UHnkgi1-QI",
        "outputId": "e9bafaf4-f96d-4579-8576-6b19b7a5940c"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "x0 = np.ones(len(x_train))\n",
        "x0 = np.reshape(x0,(len(x0),1))\n",
        "x_training = np.hstack((x0,x_train))\n",
        "x0 = np.ones(len(x_test))\n",
        "x0 = np.reshape(x0,(len(x0),1))\n",
        "x_testing = np.hstack((x0,x_test))\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "\n",
        "\n",
        "def helper_conversion(y_pred,y_true):\n",
        "\n",
        "    y_pred_help = []\n",
        "    y_true_help = []\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "\n",
        "      if y_pred[i] == -1:\n",
        "        y_pred_help.append(-1)\n",
        "      if y_pred[i] == 1:\n",
        "        y_pred_help.append(1)\n",
        "\n",
        "      #### beacuse initially weights = 0 and when predicted with x get value = 0 ######\n",
        "      if y_pred[i] == 0:\n",
        "        y_pred_help.append(0)\n",
        "\n",
        "\n",
        "\n",
        "      if y_true[i] == -1:\n",
        "        y_true_help.append(-1)\n",
        "      \n",
        "      if y_true[i] == 1:\n",
        "        y_true_help.append(1)\n",
        "\n",
        "    y_pred_help = np.array(y_pred_help)\n",
        "    y_true_help = np.array(y_true_help)\n",
        "\n",
        "    return y_pred_help,y_true_help\n",
        "\n",
        "\n",
        "def predict(x,theta):\n",
        "\n",
        "  y_pred = []\n",
        "  for i in range(len(x)):\n",
        "    pred = np.dot(x[i],theta)\n",
        "\n",
        "    y_pred.append(np.sign(pred))\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "\n",
        "def loss_function(x1,y1,theta1):\n",
        "\n",
        "  return np.log(1+np.exp(-y1*np.dot(x1,theta1)))\n",
        "\n",
        "\n",
        "\n",
        "def gradient_descent(x,y,theta,alpha):\n",
        "\n",
        "  loss = 0.0\n",
        "  temp=np.zeros_like(theta)\n",
        "\n",
        "\n",
        "  for i in range(len(x)):\n",
        "\n",
        "      temp[0] = theta[0] - alpha * 1/len(x) * -y[i] * 1 * np.exp(-y[i]*np.dot(x[i],theta)) * (1/(1+np.exp(-y[i]*np.dot(x[i],theta))))\n",
        "\n",
        "      for j in range(len(theta)-1):\n",
        "\n",
        "        gradient = -y[i] * x[i][j] * np.exp(-y[i]*np.dot(x[i],theta)) * (1/(1+np.exp(-y[i]*np.dot(x[i],theta))))\n",
        "      \n",
        "        temp[j+1] = theta[j+1] - alpha * 1/len(x) * gradient\n",
        "      \n",
        "      temp = theta\n",
        "      loss += loss_function(x[i],y[i],theta)\n",
        "\n",
        "  loss = (1/len(x)) * loss\n",
        "  return loss,theta\n",
        "\n",
        "  \n",
        "def fit(x,y,theta,alpha,epochs):\n",
        "\n",
        "  losses_per_epoch = []\n",
        "  accuracies_per_epoch = []\n",
        "\n",
        "  for e in range(1,epochs):\n",
        "    \n",
        "      loss,theta = gradient_descent(x,y,theta,alpha)\n",
        "      y_pred_training = predict(x,theta)\n",
        "      y_pred_help,y_true_help = helper_conversion(y_pred_training,y)\n",
        "      accuracy = accuracy_score(y_true = y_true_help, y_pred = y_pred_help)\n",
        "\n",
        "      print(\"epoch:\",e,\"loss:\",loss,\"accuracy:\",accuracy)#,\"weights:\",theta)\n",
        "      losses_per_epoch.append(loss)\n",
        "      accuracies_per_epoch.append(accuracy)  \n",
        "\n",
        "  \n",
        "  return loss,theta,losses_per_epoch,accuracies_per_epoch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "theta = [0.0 for t in range(0,x_train.shape[1]+1)]\n",
        "\n",
        "alpha =  0.001\n",
        "\n",
        "initial_loss = 0.0\n",
        "for i in range(len(x_training)):\n",
        "  initial_loss += loss_function(x_training[i],y_train[i],theta)\n",
        "\n",
        "# print(initial_loss)\n",
        "\n",
        "y_pred_training = predict(x_training,theta)\n",
        "y_pred_help,y_true_help = helper_conversion(y_pred_training,y_train)\n",
        "initial_accuracy = accuracy_score(y_true = y_true_help, y_pred = y_pred_help)\n",
        "\n",
        "\n",
        "print(\"epoch:\",0,\"loss:\",initial_loss/len(x_training),\"accuracy:\",initial_accuracy)\n",
        "\n",
        "\n",
        "loss_to_plot = []\n",
        "accuracy_to_plot = []\n",
        "loss_to_plot.append(initial_loss/len(x_training))\n",
        "accuracy_to_plot.append(0.0)\n",
        "\n",
        "num_of_epochs = 200\n",
        "loss,theta,losses_per_epoch,accuracies_per_epoch = fit(x_training,y_train,theta,alpha,num_of_epochs)\n",
        "loss_to_plot = loss_to_plot + losses_per_epoch\n",
        "accuracy_to_plot = accuracy_to_plot + accuracies_per_epoch\n",
        "\n",
        "\n",
        "print(np.array(theta))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "number_of_epochs = np.arange(0,num_of_epochs)\n",
        "loss_to_plot = np.array(loss_to_plot)\n",
        "print(number_of_epochs.shape)\n",
        "print(loss_to_plot.shape)\n",
        "plt.plot(number_of_epochs,loss_to_plot)\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "number_of_epochs = np.arange(0,num_of_epochs)\n",
        "accuracy_to_plot = np.array(accuracy_to_plot)\n",
        "print(number_of_epochs.shape)\n",
        "print(accuracy_to_plot.shape)\n",
        "plt.plot(number_of_epochs,accuracy_to_plot)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "y_pred_train_lor = predict(x_training,theta)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_train_lor)):\n",
        "  if y_pred_train_lor[i] == y_train[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "\n",
        "y_pred_test_lor = predict(x_testing,theta)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_test_lor)):\n",
        "  if y_pred_test_lor[i] == y_test[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "y_pred_train_acc_lor = []\n",
        "y_train_acc_lor = []\n",
        "for i in range(len(y_pred_train_lor)):\n",
        "\n",
        "  if y_pred_train_lor[i] == -1:\n",
        "    y_pred_train_acc_lor.append(-1)\n",
        "  if y_pred_train_lor[i] == 1:\n",
        "    y_pred_train_acc_lor.append(1)\n",
        "\n",
        "  if y_train[i] == -1:\n",
        "    y_train_acc_lor.append(-1)\n",
        "  \n",
        "  if y_train[i] == 1:\n",
        "    y_train_acc_lor.append(1)\n",
        "\n",
        "y_pred_train_acc_lor = np.array(y_pred_train_acc_lor)\n",
        "y_train_acc_lor = np.array(y_train_acc_lor)\n",
        "# print(y_pred_train_acc_lor)\n",
        "# print(y_train_acc_lor)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train_acc_lor, y_pred = y_pred_train_acc_lor))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train_acc_lor, y_pred_train_acc_lor).ravel()\n",
        "training_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lor:\",training_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train_acc_lor, y_pred = y_pred_train_acc_lor))\n",
        "\n",
        "\n",
        "\n",
        "y_pred_test_acc_lor = []\n",
        "y_test_acc_lor = []\n",
        "for i in range(len(y_pred_test_lor)):\n",
        "\n",
        "  if y_pred_test_lor[i] == -1:\n",
        "    y_pred_test_acc_lor.append(-1)\n",
        "  if y_pred_test_lor[i] == 1:\n",
        "    y_pred_test_acc_lor.append(1)\n",
        "\n",
        "  if y_test[i] == -1:\n",
        "    y_test_acc_lor.append(-1)\n",
        "  \n",
        "  if y_test[i] == 1:\n",
        "    y_test_acc_lor.append(1)\n",
        "\n",
        "y_pred_test_acc_lor = np.array(y_pred_test_acc_lor)\n",
        "y_test_acc_lor = np.array(y_test_acc_lor)\n",
        "# print(y_pred_test_acc_lor)\n",
        "# print(y_test_acc_lor)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test_acc_lor, y_pred = y_pred_test_acc_lor))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test_acc_lor, y_pred_test_acc_lor).ravel()\n",
        "testing_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lor:\",testing_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test_acc_lor, y_pred = y_pred_test_acc_lor))\n",
        "\n"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(455, 30)\n",
            "(455,)\n",
            "epoch: 0 loss: 0.6931471805599468 accuracy: 0.0\n",
            "epoch: 1 loss: 0.6118386769742188 accuracy: 0.6461538461538462\n",
            "epoch: 2 loss: 0.5843860168483861 accuracy: 0.7142857142857143\n",
            "epoch: 3 loss: 0.5608028601575687 accuracy: 0.778021978021978\n",
            "epoch: 4 loss: 0.5403873610396853 accuracy: 0.8043956043956044\n",
            "epoch: 5 loss: 0.5224916132674529 accuracy: 0.832967032967033\n",
            "epoch: 6 loss: 0.5066315570457696 accuracy: 0.843956043956044\n",
            "epoch: 7 loss: 0.49244173094059285 accuracy: 0.8527472527472527\n",
            "epoch: 8 loss: 0.47964321251571795 accuracy: 0.865934065934066\n",
            "epoch: 9 loss: 0.46802035082573157 accuracy: 0.8703296703296703\n",
            "epoch: 10 loss: 0.4574040332483528 accuracy: 0.8769230769230769\n",
            "epoch: 11 loss: 0.44765945929088663 accuracy: 0.8813186813186813\n",
            "epoch: 12 loss: 0.43867725332665214 accuracy: 0.8923076923076924\n",
            "epoch: 13 loss: 0.430367123092774 accuracy: 0.8967032967032967\n",
            "epoch: 14 loss: 0.422653391940531 accuracy: 0.9054945054945055\n",
            "epoch: 15 loss: 0.41547184439968887 accuracy: 0.9054945054945055\n",
            "epoch: 16 loss: 0.4087674599709079 accuracy: 0.9076923076923077\n",
            "epoch: 17 loss: 0.4024927389242893 accuracy: 0.9076923076923077\n",
            "epoch: 18 loss: 0.39660642550475306 accuracy: 0.9054945054945055\n",
            "epoch: 19 loss: 0.39107250493337775 accuracy: 0.9076923076923077\n",
            "epoch: 20 loss: 0.3858593964131471 accuracy: 0.9076923076923077\n",
            "epoch: 21 loss: 0.38093929245391744 accuracy: 0.9076923076923077\n",
            "epoch: 22 loss: 0.3762876115999454 accuracy: 0.9032967032967033\n",
            "epoch: 23 loss: 0.3718825416077399 accuracy: 0.9054945054945055\n",
            "epoch: 24 loss: 0.3677046561794158 accuracy: 0.9054945054945055\n",
            "epoch: 25 loss: 0.363736592225547 accuracy: 0.9054945054945055\n",
            "epoch: 26 loss: 0.3599627772752106 accuracy: 0.9054945054945055\n",
            "epoch: 27 loss: 0.35636919858712385 accuracy: 0.9054945054945055\n",
            "epoch: 28 loss: 0.35294320701563786 accuracy: 0.9076923076923077\n",
            "epoch: 29 loss: 0.3496733498906089 accuracy: 0.9076923076923077\n",
            "epoch: 30 loss: 0.3465492281581757 accuracy: 0.9120879120879121\n",
            "epoch: 31 loss: 0.3435613738460773 accuracy: 0.9120879120879121\n",
            "epoch: 32 loss: 0.34070114459350886 accuracy: 0.9142857142857143\n",
            "epoch: 33 loss: 0.33796063254506103 accuracy: 0.9142857142857143\n",
            "epoch: 34 loss: 0.3353325853702558 accuracy: 0.9142857142857143\n",
            "epoch: 35 loss: 0.3328103375508851 accuracy: 0.9142857142857143\n",
            "epoch: 36 loss: 0.33038775039160384 accuracy: 0.9142857142857143\n",
            "epoch: 37 loss: 0.3280591594668407 accuracy: 0.9142857142857143\n",
            "epoch: 38 loss: 0.325819328428973 accuracy: 0.9142857142857143\n",
            "epoch: 39 loss: 0.32366340827715506 accuracy: 0.9142857142857143\n",
            "epoch: 40 loss: 0.32158690132997125 accuracy: 0.9120879120879121\n",
            "epoch: 41 loss: 0.3195856292639028 accuracy: 0.9098901098901099\n",
            "epoch: 42 loss: 0.3176557046779352 accuracy: 0.9098901098901099\n",
            "epoch: 43 loss: 0.31579350572631265 accuracy: 0.9120879120879121\n",
            "epoch: 44 loss: 0.31399565342943575 accuracy: 0.9120879120879121\n",
            "epoch: 45 loss: 0.312258991329679 accuracy: 0.9120879120879121\n",
            "epoch: 46 loss: 0.3105805672064869 accuracy: 0.9120879120879121\n",
            "epoch: 47 loss: 0.3089576166050972 accuracy: 0.9120879120879121\n",
            "epoch: 48 loss: 0.3073875479669429 accuracy: 0.9098901098901099\n",
            "epoch: 49 loss: 0.305867929178318 accuracy: 0.9098901098901099\n",
            "epoch: 50 loss: 0.30439647537809517 accuracy: 0.9120879120879121\n",
            "epoch: 51 loss: 0.3029710378858779 accuracy: 0.9120879120879121\n",
            "epoch: 52 loss: 0.3015895941295764 accuracy: 0.9120879120879121\n",
            "epoch: 53 loss: 0.30025023846646964 accuracy: 0.9120879120879121\n",
            "epoch: 54 loss: 0.2989511738047503 accuracy: 0.9120879120879121\n",
            "epoch: 55 loss: 0.2976907039437317 accuracy: 0.9098901098901099\n",
            "epoch: 56 loss: 0.296467226560508 accuracy: 0.9098901098901099\n",
            "epoch: 57 loss: 0.29527922677924107 accuracy: 0.9098901098901099\n",
            "epoch: 58 loss: 0.29412527126648463 accuracy: 0.9098901098901099\n",
            "epoch: 59 loss: 0.2930040028022869 accuracy: 0.9120879120879121\n",
            "epoch: 60 loss: 0.291914135282339 accuracy: 0.9120879120879121\n",
            "epoch: 61 loss: 0.29085444911126257 accuracy: 0.9120879120879121\n",
            "epoch: 62 loss: 0.2898237869513673 accuracy: 0.9120879120879121\n",
            "epoch: 63 loss: 0.2888210497949609 accuracy: 0.9120879120879121\n",
            "epoch: 64 loss: 0.2878451933315545 accuracy: 0.9098901098901099\n",
            "epoch: 65 loss: 0.28689522458423067 accuracy: 0.9098901098901099\n",
            "epoch: 66 loss: 0.2859701987920085 accuracy: 0.9098901098901099\n",
            "epoch: 67 loss: 0.28506921651731315 accuracy: 0.9098901098901099\n",
            "epoch: 68 loss: 0.28419142095969935 accuracy: 0.9120879120879121\n",
            "epoch: 69 loss: 0.2833359954587641 accuracy: 0.9120879120879121\n",
            "epoch: 70 loss: 0.2825021611708103 accuracy: 0.9120879120879121\n",
            "epoch: 71 loss: 0.28168917490525186 accuracy: 0.9120879120879121\n",
            "epoch: 72 loss: 0.28089632710804063 accuracy: 0.9120879120879121\n",
            "epoch: 73 loss: 0.28012293998054694 accuracy: 0.9120879120879121\n",
            "epoch: 74 loss: 0.2793683657233673 accuracy: 0.9120879120879121\n",
            "epoch: 75 loss: 0.2786319848954585 accuracy: 0.9120879120879121\n",
            "epoch: 76 loss: 0.27791320487983495 accuracy: 0.9120879120879121\n",
            "epoch: 77 loss: 0.277211458447835 accuracy: 0.9120879120879121\n",
            "epoch: 78 loss: 0.27652620241462533 accuracy: 0.9120879120879121\n",
            "epoch: 79 loss: 0.27585691637924603 accuracy: 0.9120879120879121\n",
            "epoch: 80 loss: 0.27520310154305366 accuracy: 0.9120879120879121\n",
            "epoch: 81 loss: 0.27456427960092095 accuracy: 0.9120879120879121\n",
            "epoch: 82 loss: 0.2739399917000198 accuracy: 0.9120879120879121\n",
            "epoch: 83 loss: 0.2733297974614261 accuracy: 0.9120879120879121\n",
            "epoch: 84 loss: 0.27273327406016873 accuracy: 0.9120879120879121\n",
            "epoch: 85 loss: 0.27215001535968913 accuracy: 0.9120879120879121\n",
            "epoch: 86 loss: 0.27157963109699285 accuracy: 0.9120879120879121\n",
            "epoch: 87 loss: 0.27102174611506835 accuracy: 0.9120879120879121\n",
            "epoch: 88 loss: 0.2704759996393948 accuracy: 0.9120879120879121\n",
            "epoch: 89 loss: 0.2699420445956281 accuracy: 0.9120879120879121\n",
            "epoch: 90 loss: 0.26941954696574616 accuracy: 0.9120879120879121\n",
            "epoch: 91 loss: 0.2689081851801551 accuracy: 0.9120879120879121\n",
            "epoch: 92 loss: 0.2684076495434347 accuracy: 0.9120879120879121\n",
            "epoch: 93 loss: 0.2679176416915706 accuracy: 0.9120879120879121\n",
            "epoch: 94 loss: 0.26743787407868325 accuracy: 0.9120879120879121\n",
            "epoch: 95 loss: 0.26696806949139623 accuracy: 0.9142857142857143\n",
            "epoch: 96 loss: 0.2665079605891283 accuracy: 0.9142857142857143\n",
            "epoch: 97 loss: 0.26605728946870744 accuracy: 0.9142857142857143\n",
            "epoch: 98 loss: 0.2656158072518223 accuracy: 0.9142857142857143\n",
            "epoch: 99 loss: 0.2651832736939245 accuracy: 0.9142857142857143\n",
            "epoch: 100 loss: 0.2647594568132912 accuracy: 0.9142857142857143\n",
            "epoch: 101 loss: 0.26434413253905503 accuracy: 0.9142857142857143\n",
            "epoch: 102 loss: 0.2639370843770675 accuracy: 0.9142857142857143\n",
            "epoch: 103 loss: 0.2635381030925618 accuracy: 0.9142857142857143\n",
            "epoch: 104 loss: 0.26314698640863476 accuracy: 0.9142857142857143\n",
            "epoch: 105 loss: 0.2627635387196324 accuracy: 0.9142857142857143\n",
            "epoch: 106 loss: 0.26238757081859715 accuracy: 0.9142857142857143\n",
            "epoch: 107 loss: 0.2620188996379658 accuracy: 0.9142857142857143\n",
            "epoch: 108 loss: 0.2616573480027832 accuracy: 0.9142857142857143\n",
            "epoch: 109 loss: 0.261302744395732 accuracy: 0.9142857142857143\n",
            "epoch: 110 loss: 0.26095492273331505 accuracy: 0.9142857142857143\n",
            "epoch: 111 loss: 0.2606137221525906 accuracy: 0.9142857142857143\n",
            "epoch: 112 loss: 0.2602789868078754 accuracy: 0.9142857142857143\n",
            "epoch: 113 loss: 0.2599505656768793 accuracy: 0.9142857142857143\n",
            "epoch: 114 loss: 0.25962831237576806 accuracy: 0.9164835164835164\n",
            "epoch: 115 loss: 0.2593120849826725 accuracy: 0.9164835164835164\n",
            "epoch: 116 loss: 0.2590017458692006 accuracy: 0.9164835164835164\n",
            "epoch: 117 loss: 0.25869716153953776 accuracy: 0.9186813186813186\n",
            "epoch: 118 loss: 0.2583982024767265 accuracy: 0.9186813186813186\n",
            "epoch: 119 loss: 0.2581047429957683 accuracy: 0.9186813186813186\n",
            "epoch: 120 loss: 0.257816661103187 accuracy: 0.9186813186813186\n",
            "epoch: 121 loss: 0.25753383836273286 accuracy: 0.9186813186813186\n",
            "epoch: 122 loss: 0.2572561597669084 accuracy: 0.9186813186813186\n",
            "epoch: 123 loss: 0.2569835136140302 accuracy: 0.9164835164835164\n",
            "epoch: 124 loss: 0.25671579139054324 accuracy: 0.9164835164835164\n",
            "epoch: 125 loss: 0.25645288765833835 accuracy: 0.9142857142857143\n",
            "epoch: 126 loss: 0.25619469994681343 accuracy: 0.9142857142857143\n",
            "epoch: 127 loss: 0.2559411286494586 accuracy: 0.9142857142857143\n",
            "epoch: 128 loss: 0.25569207692473656 accuracy: 0.9142857142857143\n",
            "epoch: 129 loss: 0.2554474506010586 accuracy: 0.9142857142857143\n",
            "epoch: 130 loss: 0.2552071580856547 accuracy: 0.9142857142857143\n",
            "epoch: 131 loss: 0.2549711102771541 accuracy: 0.9142857142857143\n",
            "epoch: 132 loss: 0.25473922048170594 accuracy: 0.9142857142857143\n",
            "epoch: 133 loss: 0.25451140433246366 accuracy: 0.9142857142857143\n",
            "epoch: 134 loss: 0.25428757971228805 accuracy: 0.9142857142857143\n",
            "epoch: 135 loss: 0.2540676666795121 accuracy: 0.9142857142857143\n",
            "epoch: 136 loss: 0.25385158739662866 accuracy: 0.9142857142857143\n",
            "epoch: 137 loss: 0.2536392660617693 accuracy: 0.9142857142857143\n",
            "epoch: 138 loss: 0.25343062884284717 accuracy: 0.9142857142857143\n",
            "epoch: 139 loss: 0.25322560381424064 accuracy: 0.9142857142857143\n",
            "epoch: 140 loss: 0.25302412089590826 accuracy: 0.9142857142857143\n",
            "epoch: 141 loss: 0.2528261117948235 accuracy: 0.9142857142857143\n",
            "epoch: 142 loss: 0.2526315099486302 accuracy: 0.9142857142857143\n",
            "epoch: 143 loss: 0.2524402504714143 accuracy: 0.9142857142857143\n",
            "epoch: 144 loss: 0.25225227010150936 accuracy: 0.9142857142857143\n",
            "epoch: 145 loss: 0.2520675071512387 accuracy: 0.9142857142857143\n",
            "epoch: 146 loss: 0.25188590145851497 accuracy: 0.9142857142857143\n",
            "epoch: 147 loss: 0.25170739434021655 accuracy: 0.9142857142857143\n",
            "epoch: 148 loss: 0.25153192854726597 accuracy: 0.9142857142857143\n",
            "epoch: 149 loss: 0.2513594482213346 accuracy: 0.9164835164835164\n",
            "epoch: 150 loss: 0.2511898988531113 accuracy: 0.9164835164835164\n",
            "epoch: 151 loss: 0.251023227242066 accuracy: 0.9164835164835164\n",
            "epoch: 152 loss: 0.25085938145764114 accuracy: 0.9164835164835164\n",
            "epoch: 153 loss: 0.2506983108018238 accuracy: 0.9164835164835164\n",
            "epoch: 154 loss: 0.250539965773031 accuracy: 0.9164835164835164\n",
            "epoch: 155 loss: 0.2503842980312582 accuracy: 0.9164835164835164\n",
            "epoch: 156 loss: 0.25023126036444227 accuracy: 0.9164835164835164\n",
            "epoch: 157 loss: 0.25008080665598537 accuracy: 0.9164835164835164\n",
            "epoch: 158 loss: 0.24993289185339435 accuracy: 0.9164835164835164\n",
            "epoch: 159 loss: 0.24978747193799702 accuracy: 0.9164835164835164\n",
            "epoch: 160 loss: 0.24964450389568038 accuracy: 0.9164835164835164\n",
            "epoch: 161 loss: 0.24950394568862208 accuracy: 0.9164835164835164\n",
            "epoch: 162 loss: 0.24936575622797244 accuracy: 0.9164835164835164\n",
            "epoch: 163 loss: 0.24922989534744477 accuracy: 0.9164835164835164\n",
            "epoch: 164 loss: 0.24909632377778615 accuracy: 0.9164835164835164\n",
            "epoch: 165 loss: 0.24896500312209202 accuracy: 0.9164835164835164\n",
            "epoch: 166 loss: 0.2488358958319288 accuracy: 0.9164835164835164\n",
            "epoch: 167 loss: 0.24870896518423968 accuracy: 0.9164835164835164\n",
            "epoch: 168 loss: 0.2485841752589989 accuracy: 0.9164835164835164\n",
            "epoch: 169 loss: 0.248461490917588 accuracy: 0.9164835164835164\n",
            "epoch: 170 loss: 0.24834087778186922 accuracy: 0.9164835164835164\n",
            "epoch: 171 loss: 0.24822230221392388 accuracy: 0.9164835164835164\n",
            "epoch: 172 loss: 0.24810573129644004 accuracy: 0.9164835164835164\n",
            "epoch: 173 loss: 0.247991132813715 accuracy: 0.9164835164835164\n",
            "epoch: 174 loss: 0.2478784752332605 accuracy: 0.9164835164835164\n",
            "epoch: 175 loss: 0.24776772768797842 accuracy: 0.9164835164835164\n",
            "epoch: 176 loss: 0.2476588599588955 accuracy: 0.9164835164835164\n",
            "epoch: 177 loss: 0.2475518424584313 accuracy: 0.9164835164835164\n",
            "epoch: 178 loss: 0.24744664621417897 accuracy: 0.9164835164835164\n",
            "epoch: 179 loss: 0.24734324285318787 accuracy: 0.9142857142857143\n",
            "epoch: 180 loss: 0.24724160458672062 accuracy: 0.9142857142857143\n",
            "epoch: 181 loss: 0.24714170419547513 accuracy: 0.9142857142857143\n",
            "epoch: 182 loss: 0.2470435150152512 accuracy: 0.9142857142857143\n",
            "epoch: 183 loss: 0.24694701092305105 accuracy: 0.9142857142857143\n",
            "epoch: 184 loss: 0.2468521663235879 accuracy: 0.9142857142857143\n",
            "epoch: 185 loss: 0.24675895613620094 accuracy: 0.9142857142857143\n",
            "epoch: 186 loss: 0.24666735578215707 accuracy: 0.9142857142857143\n",
            "epoch: 187 loss: 0.24657734117232447 accuracy: 0.9142857142857143\n",
            "epoch: 188 loss: 0.24648888869520677 accuracy: 0.9142857142857143\n",
            "epoch: 189 loss: 0.24640197520532828 accuracy: 0.9142857142857143\n",
            "epoch: 190 loss: 0.2463165780119529 accuracy: 0.9142857142857143\n",
            "epoch: 191 loss: 0.24623267486813083 accuracy: 0.9142857142857143\n",
            "epoch: 192 loss: 0.24615024396005789 accuracy: 0.9142857142857143\n",
            "epoch: 193 loss: 0.24606926389674208 accuracy: 0.9142857142857143\n",
            "epoch: 194 loss: 0.24598971369995878 accuracy: 0.9142857142857143\n",
            "epoch: 195 loss: 0.24591157279449638 accuracy: 0.9142857142857143\n",
            "epoch: 196 loss: 0.2458348209986694 accuracy: 0.9142857142857143\n",
            "epoch: 197 loss: 0.2457594385151054 accuracy: 0.9142857142857143\n",
            "epoch: 198 loss: 0.245685405921783 accuracy: 0.9142857142857143\n",
            "epoch: 199 loss: 0.24561270416332123 accuracy: 0.9142857142857143\n",
            "[ 6.40221008e-03  6.40220789e-03  1.07315464e-02  3.32760736e-02\n",
            "  1.61675187e-02 -2.66950503e+00  4.15117355e-04 -6.68432148e-04\n",
            " -1.63448070e-03 -7.62074856e-04  7.44644146e-04  3.81228693e-04\n",
            " -6.82013992e-04  5.62366505e-03 -9.05449713e-03 -2.61441945e-01\n",
            "  4.15875700e-05 -1.24329344e-04 -2.07964987e-04 -4.46567908e-05\n",
            "  8.15079798e-05  8.61602712e-06  9.10665574e-03  4.07402499e-02\n",
            " -2.10224483e-02 -3.39683333e+00  5.60165847e-04 -2.27700156e-03\n",
            " -3.81885282e-03 -1.07027798e-03  7.98274887e-04]\n",
            "(200,)\n",
            "(200,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200,)\n",
            "(200,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "416\n",
            "39\n",
            "107\n",
            "7\n",
            "confusion_matrix:\n",
            " [[142  27]\n",
            " [ 12 274]]\n",
            "142 27 12 274\n",
            "training accuracy_lor: 91.42857142857143 %\n",
            "0.9142857142857143\n",
            "confusion_matrix:\n",
            " [[38  5]\n",
            " [ 2 69]]\n",
            "38 5 2 69\n",
            "testing accuracy_lor: 93.85964912280701 %\n",
            "0.9385964912280702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUenAAw_4aIg"
      },
      "source": [
        "# sklearn logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_yvP03O4Dc8",
        "outputId": "280d56c6-52d4-42ee-a4e8-ad0225ddb37d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression().fit(x_train, y_train)  \n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train, y_pred = clf.predict(x_train)))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train, clf.predict(x_train)).ravel()\n",
        "training_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lor:\",training_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train, y_pred = clf.predict(x_train)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test, y_pred = clf.predict(x_test)))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test, clf.predict(x_test)).ravel()\n",
        "testing_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lor:\",testing_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test, y_pred = clf.predict(x_test)))"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[154  15]\n",
            " [ 10 276]]\n",
            "154 15 10 276\n",
            "training accuracy_lor: 94.5054945054945 %\n",
            "0.945054945054945\n",
            "confusion_matrix:\n",
            " [[40  3]\n",
            " [ 1 70]]\n",
            "40 3 1 70\n",
            "testing accuracy_lor: 96.49122807017544 %\n",
            "0.9649122807017544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-etUcWU6FU6"
      },
      "source": [
        "## **90:10 (train:test) split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJQlAB7E4kiG",
        "outputId": "e9eae8a2-ff2d-4c4b-cb3b-f3a336f5f089"
      },
      "source": [
        "print(X1.shape)\n",
        "print(Y1.shape)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBTRibp-6VHR",
        "outputId": "956b3945-ea2b-4a23-e69f-d2a4a006bb69"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X1,Y1,test_size = 0.1,shuffle = True,random_state = 42)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 30)\n",
            "(57, 30)\n",
            "(512,)\n",
            "(57,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh46iNsy69B6"
      },
      "source": [
        "# Data Preprocessing for Half-Space Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyar2Hna6-W-",
        "outputId": "537ff4a6-06fb-4fb9-8708-6e70b57b3e1a"
      },
      "source": [
        "X_Malign = []\n",
        "X_Benign = []\n",
        "Y_Malign = []\n",
        "Y_Benign = []\n",
        "\n",
        "for i in range(len(x_train)):\n",
        "\n",
        "  if y_train[i] == -1:\n",
        "    X_Malign.append(x_train[i])\n",
        "    Y_Malign.append(y_train[i])\n",
        "    \n",
        "  elif y_train[i] == 1:\n",
        "    X_Benign.append(x_train[i])\n",
        "    Y_Benign.append(y_train[i])\n",
        "\n",
        "X_Malign = np.array(X_Malign)\n",
        "X_Benign = np.array(X_Benign)\n",
        "\n",
        "print(X_Malign.shape)\n",
        "print(X_Benign.shape)\n",
        "\n",
        "\n",
        "def euclidean_distance(x1,c_):\n",
        "  \n",
        "  dist = np.sqrt(np.sum((x1-c_)**2))\n",
        "\n",
        "  return dist\n",
        "\n",
        "# centroidd of Malign data\n",
        "X_Malign_Centroid = X_Malign.mean(axis = 0)\n",
        "X_Benign_Centroid = X_Benign.mean(axis = 0)\n",
        "\n",
        "distance_Benign = []\n",
        "distance_Malign = []\n",
        "\n",
        "X_redundant_points = []\n",
        "Y_redundant_points = []\n",
        "\n",
        "X_sep= []\n",
        "Y_sep = []\n",
        "\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "\n",
        "  dist_Malign = euclidean_distance(x_train[i],X_Malign_Centroid) \n",
        "  dist_Benign = euclidean_distance(x_train[i],X_Benign_Centroid) \n",
        "\n",
        "  if y_train[i] == -1 and dist_Malign < dist_Benign and dist_Malign <= 1000: # -1:M, 1:B # correct\n",
        "\n",
        "    # X_Malign_sep.append(x_train[i])\n",
        "    # Y_Malign.append(y_train[i])\n",
        "    X_sep.append(x_train[i])\n",
        "    Y_sep.append(y_train[i])\n",
        "    distance_Malign.append(dist_Malign)\n",
        "  \n",
        "  elif y_train[i] == -1 and dist_Malign > dist_Benign: # incorrect\n",
        "    \n",
        "    X_redundant_points.append(x_train[i])\n",
        "    Y_redundant_points.append(y_train[i])\n",
        "\n",
        "\n",
        "  elif y_train[i] == 1 and dist_Benign < dist_Malign and dist_Benign <= 200  : # -1:M, 1:B # correct\n",
        "\n",
        "    # X_Malign_sep.append(x_train[i])\n",
        "    # Y_Malign.append(y_train[i])\n",
        "    X_sep.append(x_train[i])\n",
        "    Y_sep.append(y_train[i])\n",
        "    distance_Benign.append(dist_Benign)\n",
        "  \n",
        "  elif y_train[i] == 1 and dist_Benign > dist_Malign: # incorrect\n",
        "    \n",
        "    X_redundant_points.append(x_train[i])\n",
        "    Y_redundant_points.append(y_train[i])\n",
        "\n",
        "X_sep = np.array(X_sep)\n",
        "Y_sep = np.array(Y_sep)\n",
        "\n",
        "print(X_sep.shape)\n",
        "print(Y_sep.shape)\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(195, 30)\n",
            "(317, 30)\n",
            "(326, 30)\n",
            "(326,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF_HjhL27ERF"
      },
      "source": [
        "\n",
        "**PCA on Linearly Seperable Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "bHd89_756_Dp",
        "outputId": "9ccc6f9b-e245-4610-ee0e-f977daeec187"
      },
      "source": [
        "# PCA on Linearly Seperable Dataset\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(X_sep)\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
        "Y_df = pd.DataFrame(Y_sep,columns=['target'])\n",
        "finalDf = pd.concat([principalDf, Y_df[['target']]], axis = 1)\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('2 component PCA', fontsize = 20)\n",
        "targets = [1,-1]\n",
        "colors = ['r', 'g']\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['target'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1'], finalDf.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN0dftJn7NVx"
      },
      "source": [
        "# LP Solver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC88KbgT7E-h",
        "outputId": "b200779c-efb1-4fb8-fed7-f7b1e3108b7d"
      },
      "source": [
        "from scipy.optimize import linprog\n",
        "A = []\n",
        "for i in range(len(X_sep)):\n",
        "  A.append(X_sep[i]*Y_sep[i]) \n",
        "A = -1*np.array(A)\n",
        "print(A.shape)\n",
        "\n",
        "V = -1*np.ones(len(Y_sep))\n",
        "V = np.reshape(V,(len(V),1))\n",
        "print(V.shape)\n",
        "\n",
        "\n",
        "obj = [0 for j in range(np.array(X_sep).shape[1])]\n",
        "\n",
        "lhs_ineq = []\n",
        "rhs_ineq = []\n",
        "\n",
        "for i in range(len(A)):\n",
        "  lhs_ineq.append(list(A[i]))\n",
        "  rhs_ineq.append(V[i])\n",
        "bnd=(None,None)\n",
        "opt = linprog(c=obj,A_ub=lhs_ineq,b_ub=rhs_ineq,bounds=bnd,method ='simplex',options={\"disp\": True})\n",
        "\n",
        "\n",
        "print(opt)\n",
        "weights = opt['x']\n",
        "print(weights.shape)\n",
        "\n",
        "optimized_weights = []\n",
        "for i in weights:\n",
        "  optimized_weights.append(i)\n",
        "optimized_weights = np.array(optimized_weights)\n",
        "\n",
        "y_pred_train_lp = np.sign(np.matmul(X_sep,optimized_weights))\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_train_lp)):\n",
        "  if y_pred_train_lp[i] == Y_sep[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "y_pred_train_acc_lp = []\n",
        "y_train_acc_lp = []\n",
        "for i in range(len(y_pred_train_lp)):\n",
        "\n",
        "  if y_pred_train_lp[i] == -1:\n",
        "    y_pred_train_acc_lp.append(-1)\n",
        "  if y_pred_train_lp[i] == 1:\n",
        "    y_pred_train_acc_lp.append(1)\n",
        "\n",
        "  if Y_sep[i] == -1:\n",
        "    y_train_acc_lp.append(-1)\n",
        "  \n",
        "  if Y_sep[i] == 1:\n",
        "    y_train_acc_lp.append(1)\n",
        "\n",
        "y_pred_train_acc_lp = np.array(y_pred_train_acc_lp)\n",
        "y_train_acc_lp = np.array(y_train_acc_lp)\n",
        "# print(y_pred_train_acc_lp)\n",
        "# print(y_train_acc_lp)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train_acc_lp, y_pred_train_acc_lp).ravel()\n",
        "training_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lp:\",training_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "\n",
        "\n",
        "y_pred_test_lp = np.sign(np.matmul(x_test,optimized_weights))\n",
        "# y_test_true = np.array(y_test)\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "  if y_pred_test_lp[i] == y_test[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "\n",
        "y_pred_test_acc_lp = []\n",
        "y_test_acc_lp = []\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "\n",
        "  if y_pred_test_lp[i] == -1:\n",
        "    y_pred_test_acc_lp.append(-1)\n",
        "  if y_pred_test_lp[i] == 1:\n",
        "    y_pred_test_acc_lp.append(1)\n",
        "\n",
        "  if y_test[i] == -1:\n",
        "    y_test_acc_lp.append(-1)\n",
        "  \n",
        "  if y_test[i] == 1:\n",
        "    y_test_acc_lp.append(1)\n",
        "\n",
        "y_pred_test_acc_lp = np.array(y_pred_test_acc_lp)\n",
        "y_test_acc_lp = np.array(y_test_acc_lp)\n",
        "# print(y_pred_test_acc_lp)\n",
        "# print(y_test_acc_lp)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test_acc_lp, y_pred_test_acc_lp).ravel()\n",
        "testing_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lp:\",testing_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "\n"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(326, 30)\n",
            "(326, 1)\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.000000    \n",
            "         Iterations: 642\n",
            "     con: array([], dtype=float64)\n",
            "     fun: 0.0\n",
            " message: 'Optimization terminated successfully.'\n",
            "     nit: 642\n",
            "   slack: array([ 2.75198725e+00,  1.40062266e+00,  1.49577139e+01,  2.11250301e+01,\n",
            "        1.98541454e+00,  1.07069992e+00,  5.87169892e+00,  7.64716279e+00,\n",
            "        1.28655120e+00,  3.38502397e+00,  3.96771172e+00,  9.14898937e-02,\n",
            "        7.89367781e-01,  4.32183357e-01,  3.97343150e+00,  5.07183652e+00,\n",
            "        3.29208102e+00,  3.92140013e+00,  2.13699283e+01,  5.61629700e+00,\n",
            "        8.94682694e+00,  3.63401635e+00,  2.37776468e+00,  2.66456155e+00,\n",
            "        1.03003289e+00,  1.75524083e+00,  2.96422343e+00,  1.44040986e+01,\n",
            "        6.53699317e-13,  2.85104653e+00,  6.16543542e+00,  4.91038776e+00,\n",
            "        1.40260458e+01,  6.83230906e+00,  6.03423179e+00,  4.56882737e+00,\n",
            "        2.16520027e+00,  3.57685147e+00,  2.77667443e+00,  2.03316803e+01,\n",
            "        3.74913208e+00,  2.90199374e+00,  2.20977679e+00,  9.39207598e+00,\n",
            "        3.47715155e+00,  1.83212388e+01,  6.53318137e-01,  4.37731984e-01,\n",
            "        1.55186047e+01,  1.53745820e+01,  2.55509771e+00,  3.11790023e-01,\n",
            "        1.41621075e+00,  3.37266863e+00,  1.08201859e+00,  2.92961362e+00,\n",
            "        7.25040943e+00,  1.02487292e+01,  6.26744797e-01,  1.15026865e+00,\n",
            "        2.51254335e+00,  8.66131793e-01,  3.31517039e+00,  7.84084576e+00,\n",
            "        2.36769943e+00,  5.21200544e+00,  3.41012004e+00,  6.18368308e+00,\n",
            "        1.20823366e+00,  4.59359516e+00,  2.90946493e-01,  1.59784398e+00,\n",
            "        5.02088681e+00,  2.94352040e+00,  8.97896507e-01,  4.47058103e+00,\n",
            "        4.36490828e+00,  1.23945625e+01,  8.91868506e-01,  2.82537345e+00,\n",
            "        4.74380131e-02,  2.23355414e+01,  2.34477148e+00,  2.59676931e+00,\n",
            "        3.70471829e+00,  3.63270945e+00,  5.94424327e+00,  1.21804481e+00,\n",
            "        4.59910144e+00,  3.25491311e+00,  1.54994317e+00,  1.57055490e+00,\n",
            "        1.15426766e+01,  1.74897341e+01,  3.94944903e+00,  2.64361873e+00,\n",
            "        1.11114001e+00,  2.96883162e+00,  3.37449623e+00,  1.61484962e+00,\n",
            "        1.45533513e+00,  3.60703634e+00,  1.28357141e+00,  2.03161095e+01,\n",
            "        4.15131119e+00,  1.32759869e+00,  2.08621584e+00,  2.95663247e+00,\n",
            "        2.53949833e+00,  2.50018099e+00,  1.44564796e+00,  3.25036345e+00,\n",
            "        8.13571432e-13, -5.96855898e-13,  8.04820706e-01,  8.14454665e-01,\n",
            "        1.33507008e+01,  9.73373039e+00,  8.12162680e-01,  6.23003298e-01,\n",
            "        2.60804593e+00,  1.41713700e+00,  2.78069288e+00,  6.94724590e+00,\n",
            "        1.59096272e+00,  3.50491943e+00,  3.30626532e+00, -5.32907052e-13,\n",
            "        1.10564958e+01,  1.05050533e+00,  2.38307840e+00,  2.18149195e+00,\n",
            "        1.73604760e+00,  3.20712221e+00,  5.33849105e+00,  9.70902387e+00,\n",
            "        3.20320474e+00,  3.77014722e+00,  1.19400367e+01,  1.48160053e-01,\n",
            "        4.16282664e+00,  1.96782783e+00,  8.19820866e-01,  4.87269864e+00,\n",
            "        3.37921765e+00,  3.08996737e+00,  3.30636298e+00,  5.51627384e-01,\n",
            "        1.84333638e+00,  3.69662682e+00,  3.32770751e+00,  1.76472737e+00,\n",
            "        4.82683551e+00,  1.37994116e+01,  3.60093760e+00,  1.11912313e+00,\n",
            "        1.76753751e+00,  4.24117218e+00,  7.37294271e+00,  1.45704020e+00,\n",
            "        5.89024959e+00,  4.55074637e+00,  2.91227822e+00,  9.34045910e+00,\n",
            "        7.36675756e-01,  2.70526759e+00,  2.24359419e+00,  5.52980442e+00,\n",
            "        1.39958234e+01,  3.34380783e+00,  1.32559985e+01,  2.77933365e+00,\n",
            "        1.01530556e+01,  2.48810054e+00,  1.93283605e+01,  1.61016111e+01,\n",
            "        2.21705668e-01,  1.33282505e+01,  1.45329506e+01,  7.38731522e+00,\n",
            "        2.79727081e+00,  8.73967565e-13,  3.53652933e+00,  8.81842226e+00,\n",
            "        1.35751777e+01,  5.14806535e+00,  1.39127393e+00,  5.73024300e+00,\n",
            "        3.37618823e+00,  1.65212155e+00,  1.97753723e+00,  2.75245633e+00,\n",
            "        9.84878479e+00,  1.64510747e+01,  1.42920537e+00,  1.09243225e+01,\n",
            "        5.33515971e+00,  1.62540501e+01,  8.58138486e-01,  3.64411149e+00,\n",
            "        1.02171551e+01,  3.74986554e+00,  6.44914779e+00,  7.81597009e-13,\n",
            "        2.84010853e+00,  1.98252717e+00,  3.01965576e+00,  2.07710567e+00,\n",
            "        1.50370652e+00,  7.42452085e+00,  8.33577629e+00,  3.29511046e+00,\n",
            "        1.15655506e+00,  1.81129757e+00,  2.92247875e+00,  4.43520988e+00,\n",
            "        5.63512143e-01,  9.55172704e+00,  5.68467015e+00,  7.81125550e+00,\n",
            "        3.90836545e+00,  8.38440428e-13,  3.91838590e+00,  8.88178420e-13,\n",
            "        2.59353753e+00,  2.90486560e+00,  3.19206373e+00,  3.91752094e+00,\n",
            "        1.53569855e+00,  2.22337146e+00,  1.39921736e+01,  1.40840722e+00,\n",
            "        7.55094361e-03,  6.82888231e-01,  1.14141125e-01,  3.21106820e+00,\n",
            "        1.03185292e+01,  1.71721873e+00,  1.73783362e+01,  1.69030579e+00,\n",
            "        1.08786647e+01,  1.29550365e+01,  3.34987015e+00,  2.87046235e+00,\n",
            "        3.37419803e+00,  3.08166102e+00,  5.62719620e-01,  7.00646672e+00,\n",
            "        1.19179351e+01,  2.07895012e+00,  2.17936239e+00,  2.45676641e+00,\n",
            "        1.13689598e+01,  7.59087811e+00,  3.59399907e+00,  4.25544801e+00,\n",
            "        1.56628938e+01,  9.60651767e-01,  2.42598240e+00,  2.15274695e+00,\n",
            "        2.40355097e+01,  1.12442341e+01,  9.47156393e-01,  3.51099272e+00,\n",
            "        1.81089442e+01,  7.30881604e+00,  3.03271037e+00,  1.75014012e+00,\n",
            "        3.07875716e+00,  2.10242155e+00,  1.80231063e+00,  2.35121257e+00,\n",
            "        2.77567828e+00,  1.63228242e+01,  3.95865949e+00,  3.48837885e-01,\n",
            "        3.88540159e+00,  4.21409816e+00,  1.20923354e+00,  3.98550176e-01,\n",
            "        2.65926129e+00,  2.93961916e+00,  4.01889396e+00,  1.26128559e-01,\n",
            "        2.51420852e+00,  2.30094570e+00,  8.53724699e+00,  2.60987501e+00,\n",
            "        1.46050038e+00,  6.21724894e-13,  4.77536491e+00,  1.96670714e+01,\n",
            "        2.48402252e+00,  3.01532903e+00,  4.98108746e+00,  5.41707191e+00,\n",
            "        1.26391003e+00,  8.51536241e+00,  1.24044778e+00,  1.35318891e+00,\n",
            "        2.93221371e+00,  9.76331822e+00,  1.05333142e+00, -5.75539616e-13,\n",
            "        2.21359814e+00,  1.86997757e+00,  2.40512134e+00,  1.31215333e+00,\n",
            "        4.20239423e+00,  1.94962213e+01,  3.03475829e+00,  4.82431142e+00,\n",
            "        2.69683526e+00,  3.93544986e+00,  5.90825648e+00,  1.77269975e-01,\n",
            "        3.86376412e+00,  1.02037497e+01,  8.42590444e+00,  1.13749274e+00,\n",
            "        1.35444004e+00,  1.46937087e+00,  1.10186586e+01,  1.59943847e+00,\n",
            "        3.88136566e+00,  2.10375556e+00])\n",
            "  status: 0\n",
            " success: True\n",
            "       x: array([ 0.        , -0.11874979, -0.32578092,  0.01459538,  0.        ,\n",
            "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
            "        0.        , -0.58518658,  1.72160348, -0.08475482,  0.        ,\n",
            "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
            "        1.8368788 ,  0.10888237,  0.19624341, -0.03751124,  0.        ,\n",
            "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])\n",
            "(30,)\n",
            "326\n",
            "0\n",
            "confusion_matrix:\n",
            " [[120   0]\n",
            " [  0 206]]\n",
            "120 0 0 206\n",
            "training accuracy_lp: 100.0 %\n",
            "1.0\n",
            "54\n",
            "3\n",
            "confusion_matrix:\n",
            " [[16  1]\n",
            " [ 2 38]]\n",
            "16 1 2 38\n",
            "testing accuracy_lp: 94.73684210526315 %\n",
            "0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIE_Uf_w7WTt"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8otTJXt7Piv",
        "outputId": "4c109916-5a90-425d-cb53-7f242426f312"
      },
      "source": [
        "def perceptron(x_train,y_train):\n",
        "\n",
        "  weights = np.zeros(x_train.shape[1])\n",
        "  \n",
        "  flag = 0\n",
        "  t = 0\n",
        "  while(flag == 0):\n",
        "  # for t in range(num_iterations):\n",
        "    flag = 1\n",
        "    for i in range(len(x_train)):\n",
        "      if y_train[i]*np.sum(x_train[i]*weights) <= 0:\n",
        "        flag = 0\n",
        "        weights = weights + y_train[i]*x_train[i]\n",
        "    # print(weights)\n",
        "    t+=1\n",
        "\n",
        "  return weights,t\n",
        "  \n",
        "w,t = perceptron(X_sep,Y_sep)\n",
        "print(w,t)\n",
        "\n",
        "print(\"weights:\\n\",w,\"\\n num_of_iterations:\",t)\n",
        "\n",
        "y_pred_train_per = np.sign(np.matmul(X_sep,w))\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_train_per)):\n",
        "  if y_pred_train_per[i] == Y_sep[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "y_pred_train_acc_lp = []\n",
        "y_train_acc_lp = []\n",
        "for i in range(len(y_pred_train_lp)):\n",
        "\n",
        "  if y_pred_train_lp[i] == -1:\n",
        "    y_pred_train_acc_lp.append(-1)\n",
        "  if y_pred_train_lp[i] == 1:\n",
        "    y_pred_train_acc_lp.append(1)\n",
        "\n",
        "  if Y_sep[i] == -1:\n",
        "    y_train_acc_lp.append(-1)\n",
        "  \n",
        "  if Y_sep[i] == 1:\n",
        "    y_train_acc_lp.append(1)\n",
        "\n",
        "y_pred_train_acc_lp = np.array(y_pred_train_acc_lp)\n",
        "y_train_acc_lp = np.array(y_train_acc_lp)\n",
        "# print(y_pred_train_acc_lp)\n",
        "# print(y_train_acc_lp)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train_acc_lp, y_pred_train_acc_lp).ravel()\n",
        "training_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lp:\",training_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train_acc_lp, y_pred = y_pred_train_acc_lp))\n",
        "\n",
        "\n",
        "y_pred_test_lp = np.sign(np.matmul(x_test,w))\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "  if y_pred_test_lp[i] == y_test[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "y_pred_test_acc_lp = []\n",
        "y_test_acc_lp = []\n",
        "for i in range(len(y_pred_test_lp)):\n",
        "\n",
        "  if y_pred_test_lp[i] == -1:\n",
        "    y_pred_test_acc_lp.append(-1)\n",
        "  if y_pred_test_lp[i] == 1:\n",
        "    y_pred_test_acc_lp.append(1)\n",
        "\n",
        "  if y_test[i] == -1:\n",
        "    y_test_acc_lp.append(-1)\n",
        "  \n",
        "  if y_test[i] == 1:\n",
        "    y_test_acc_lp.append(1)\n",
        "\n",
        "y_pred_test_acc_lp = np.array(y_pred_test_acc_lp)\n",
        "y_test_acc_lp = np.array(y_test_acc_lp)\n",
        "# print(y_pred_test_acc_lp)\n",
        "# print(y_test_acc_lp)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test_acc_lp, y_pred_test_acc_lp).ravel()\n",
        "testing_accuracy_lp = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lp:\",testing_accuracy_lp*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test_acc_lp, y_pred = y_pred_test_acc_lp))\n",
        "\n",
        "\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.92118000e+03  3.08057000e+03  1.15929300e+04  1.65460000e+03\n",
            "  2.22015800e+01  6.37014000e+00 -1.90215729e+01 -7.05977600e+00\n",
            "  3.97392000e+01  1.62545800e+01  2.62567000e+01  1.90607200e+02\n",
            "  1.29070500e+02 -1.89455300e+03  7.67934000e-01 -9.26980000e-02\n",
            " -3.00583200e+00 -1.43349000e-01  4.21163700e+00  3.29323400e-01\n",
            "  2.07390000e+03  4.08115000e+03  1.23354200e+04 -4.57400000e+03\n",
            "  2.95665000e+01  1.19141300e+01 -2.27087860e+01 -2.35929800e+00\n",
            "  6.45060000e+01  1.92959000e+01] 29\n",
            "weights:\n",
            " [ 1.92118000e+03  3.08057000e+03  1.15929300e+04  1.65460000e+03\n",
            "  2.22015800e+01  6.37014000e+00 -1.90215729e+01 -7.05977600e+00\n",
            "  3.97392000e+01  1.62545800e+01  2.62567000e+01  1.90607200e+02\n",
            "  1.29070500e+02 -1.89455300e+03  7.67934000e-01 -9.26980000e-02\n",
            " -3.00583200e+00 -1.43349000e-01  4.21163700e+00  3.29323400e-01\n",
            "  2.07390000e+03  4.08115000e+03  1.23354200e+04 -4.57400000e+03\n",
            "  2.95665000e+01  1.19141300e+01 -2.27087860e+01 -2.35929800e+00\n",
            "  6.45060000e+01  1.92959000e+01] \n",
            " num_of_iterations: 29\n",
            "326\n",
            "0\n",
            "confusion_matrix:\n",
            " [[120   0]\n",
            " [  0 206]]\n",
            "120 0 0 206\n",
            "training accuracy_lp: 100.0 %\n",
            "1.0\n",
            "54\n",
            "3\n",
            "confusion_matrix:\n",
            " [[17  0]\n",
            " [ 3 37]]\n",
            "17 0 3 37\n",
            "testing accuracy_lp: 94.73684210526315 %\n",
            "0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xc_WfS57Xnj"
      },
      "source": [
        "# Logistic Regression Classifier (Scratch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m92aD6OD7W9M",
        "outputId": "d0c0cf18-a132-402d-d95f-27c53a579acf"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "x0 = np.ones(len(x_train))\n",
        "x0 = np.reshape(x0,(len(x0),1))\n",
        "x_training = np.hstack((x0,x_train))\n",
        "x0 = np.ones(len(x_test))\n",
        "x0 = np.reshape(x0,(len(x0),1))\n",
        "x_testing = np.hstack((x0,x_test))\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "\n",
        "\n",
        "def helper_conversion(y_pred,y_true):\n",
        "\n",
        "    y_pred_help = []\n",
        "    y_true_help = []\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "\n",
        "      if y_pred[i] == -1:\n",
        "        y_pred_help.append(-1)\n",
        "      if y_pred[i] == 1:\n",
        "        y_pred_help.append(1)\n",
        "\n",
        "      #### beacuse initially weights = 0 and when predicted with x get value = 0 ######\n",
        "      if y_pred[i] == 0:\n",
        "        y_pred_help.append(0)\n",
        "\n",
        "\n",
        "\n",
        "      if y_true[i] == -1:\n",
        "        y_true_help.append(-1)\n",
        "      \n",
        "      if y_true[i] == 1:\n",
        "        y_true_help.append(1)\n",
        "\n",
        "    y_pred_help = np.array(y_pred_help)\n",
        "    y_true_help = np.array(y_true_help)\n",
        "\n",
        "    return y_pred_help,y_true_help\n",
        "\n",
        "\n",
        "def predict(x,theta):\n",
        "\n",
        "  y_pred = []\n",
        "  for i in range(len(x)):\n",
        "    pred = np.dot(x[i],theta)\n",
        "\n",
        "    y_pred.append(np.sign(pred))\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "\n",
        "def loss_function(x1,y1,theta1):\n",
        "\n",
        "  return np.log(1+np.exp(-y1*np.dot(x1,theta1)))\n",
        "\n",
        "\n",
        "\n",
        "def gradient_descent(x,y,theta,alpha):\n",
        "\n",
        "  loss = 0.0\n",
        "  temp=np.zeros_like(theta)\n",
        "\n",
        "\n",
        "  for i in range(len(x)):\n",
        "\n",
        "      temp[0] = theta[0] - alpha * 1/len(x) * -y[i] * 1 * np.exp(-y[i]*np.dot(x[i],theta)) * (1/(1+np.exp(-y[i]*np.dot(x[i],theta))))\n",
        "\n",
        "      for j in range(len(theta)-1):\n",
        "\n",
        "        gradient = -y[i] * x[i][j] * np.exp(-y[i]*np.dot(x[i],theta)) * (1/(1+np.exp(-y[i]*np.dot(x[i],theta))))\n",
        "      \n",
        "        temp[j+1] = theta[j+1] - alpha * 1/len(x) * gradient\n",
        "      \n",
        "      temp = theta\n",
        "      loss += loss_function(x[i],y[i],theta)\n",
        "\n",
        "  loss = (1/len(x)) * loss\n",
        "  return loss,theta\n",
        "\n",
        "  \n",
        "def fit(x,y,theta,alpha,epochs):\n",
        "\n",
        "  losses_per_epoch = []\n",
        "  accuracies_per_epoch = []\n",
        "\n",
        "  for e in range(1,epochs):\n",
        "    \n",
        "      loss,theta = gradient_descent(x,y,theta,alpha)\n",
        "      y_pred_training = predict(x,theta)\n",
        "      y_pred_help,y_true_help = helper_conversion(y_pred_training,y)\n",
        "      accuracy = accuracy_score(y_true = y_true_help, y_pred = y_pred_help)\n",
        "\n",
        "      print(\"epoch:\",e,\"loss:\",loss,\"accuracy:\",accuracy)#,\"weights:\",theta)\n",
        "      losses_per_epoch.append(loss)\n",
        "      accuracies_per_epoch.append(accuracy)  \n",
        "\n",
        "  \n",
        "  return loss,theta,losses_per_epoch,accuracies_per_epoch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "theta = [0.0 for t in range(0,x_train.shape[1]+1)]\n",
        "\n",
        "alpha =  0.001\n",
        "\n",
        "initial_loss = 0.0\n",
        "for i in range(len(x_training)):\n",
        "  initial_loss += loss_function(x_training[i],y_train[i],theta)\n",
        "\n",
        "# print(initial_loss)\n",
        "\n",
        "y_pred_training = predict(x_training,theta)\n",
        "y_pred_help,y_true_help = helper_conversion(y_pred_training,y_train)\n",
        "initial_accuracy = accuracy_score(y_true = y_true_help, y_pred = y_pred_help)\n",
        "\n",
        "\n",
        "print(\"epoch:\",0,\"loss:\",initial_loss/len(x_training),\"accuracy:\",initial_accuracy)\n",
        "\n",
        "\n",
        "loss_to_plot = []\n",
        "accuracy_to_plot = []\n",
        "loss_to_plot.append(initial_loss/len(x_training))\n",
        "accuracy_to_plot.append(0.0)\n",
        "\n",
        "num_of_epochs = 200\n",
        "loss,theta,losses_per_epoch,accuracies_per_epoch = fit(x_training,y_train,theta,alpha,num_of_epochs)\n",
        "loss_to_plot = loss_to_plot + losses_per_epoch\n",
        "accuracy_to_plot = accuracy_to_plot + accuracies_per_epoch\n",
        "\n",
        "\n",
        "print(np.array(theta))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "number_of_epochs = np.arange(0,num_of_epochs)\n",
        "loss_to_plot = np.array(loss_to_plot)\n",
        "print(number_of_epochs.shape)\n",
        "print(loss_to_plot.shape)\n",
        "plt.plot(number_of_epochs,loss_to_plot)\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "number_of_epochs = np.arange(0,num_of_epochs)\n",
        "accuracy_to_plot = np.array(accuracy_to_plot)\n",
        "print(number_of_epochs.shape)\n",
        "print(accuracy_to_plot.shape)\n",
        "plt.plot(number_of_epochs,accuracy_to_plot)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "y_pred_train_lor = predict(x_training,theta)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_train_lor)):\n",
        "  if y_pred_train_lor[i] == y_train[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "\n",
        "y_pred_test_lor = predict(x_testing,theta)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "\n",
        "for i in range(len(y_pred_test_lor)):\n",
        "  if y_pred_test_lor[i] == y_test[i]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    incorrect+=1\n",
        "    \n",
        "print(correct)\n",
        "print(incorrect)\n",
        "\n",
        "\n",
        "y_pred_train_acc_lor = []\n",
        "y_train_acc_lor = []\n",
        "for i in range(len(y_pred_train_lor)):\n",
        "\n",
        "  if y_pred_train_lor[i] == -1:\n",
        "    y_pred_train_acc_lor.append(-1)\n",
        "  if y_pred_train_lor[i] == 1:\n",
        "    y_pred_train_acc_lor.append(1)\n",
        "\n",
        "  if y_train[i] == -1:\n",
        "    y_train_acc_lor.append(-1)\n",
        "  \n",
        "  if y_train[i] == 1:\n",
        "    y_train_acc_lor.append(1)\n",
        "\n",
        "y_pred_train_acc_lor = np.array(y_pred_train_acc_lor)\n",
        "y_train_acc_lor = np.array(y_train_acc_lor)\n",
        "# print(y_pred_train_acc_lor)\n",
        "# print(y_train_acc_lor)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train_acc_lor, y_pred = y_pred_train_acc_lor))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train_acc_lor, y_pred_train_acc_lor).ravel()\n",
        "training_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lor:\",training_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train_acc_lor, y_pred = y_pred_train_acc_lor))\n",
        "\n",
        "\n",
        "\n",
        "y_pred_test_acc_lor = []\n",
        "y_test_acc_lor = []\n",
        "for i in range(len(y_pred_test_lor)):\n",
        "\n",
        "  if y_pred_test_lor[i] == -1:\n",
        "    y_pred_test_acc_lor.append(-1)\n",
        "  if y_pred_test_lor[i] == 1:\n",
        "    y_pred_test_acc_lor.append(1)\n",
        "\n",
        "  if y_test[i] == -1:\n",
        "    y_test_acc_lor.append(-1)\n",
        "  \n",
        "  if y_test[i] == 1:\n",
        "    y_test_acc_lor.append(1)\n",
        "\n",
        "y_pred_test_acc_lor = np.array(y_pred_test_acc_lor)\n",
        "y_test_acc_lor = np.array(y_test_acc_lor)\n",
        "# print(y_pred_test_acc_lor)\n",
        "# print(y_test_acc_lor)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test_acc_lor, y_pred = y_pred_test_acc_lor))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test_acc_lor, y_pred_test_acc_lor).ravel()\n",
        "testing_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lor:\",testing_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test_acc_lor, y_pred = y_pred_test_acc_lor))\n",
        "\n"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 30)\n",
            "(512,)\n",
            "epoch: 0 loss: 0.6931471805599468 accuracy: 0.0\n",
            "epoch: 1 loss: 0.6169617931522426 accuracy: 0.642578125\n",
            "epoch: 2 loss: 0.5879534258733421 accuracy: 0.71875\n",
            "epoch: 3 loss: 0.562550299547438 accuracy: 0.783203125\n",
            "epoch: 4 loss: 0.5407568071161529 accuracy: 0.814453125\n",
            "epoch: 5 loss: 0.5217851177912397 accuracy: 0.8359375\n",
            "epoch: 6 loss: 0.5050578777934555 accuracy: 0.84765625\n",
            "epoch: 7 loss: 0.49015011649672197 accuracy: 0.859375\n",
            "epoch: 8 loss: 0.4767452548295388 accuracy: 0.865234375\n",
            "epoch: 9 loss: 0.4646032897235312 accuracy: 0.873046875\n",
            "epoch: 10 loss: 0.45353853705327984 accuracy: 0.880859375\n",
            "epoch: 11 loss: 0.4434041471417991 accuracy: 0.88671875\n",
            "epoch: 12 loss: 0.43408144715974095 accuracy: 0.89453125\n",
            "epoch: 13 loss: 0.4254726760340041 accuracy: 0.900390625\n",
            "epoch: 14 loss: 0.41749602155692567 accuracy: 0.900390625\n",
            "epoch: 15 loss: 0.41008217189937995 accuracy: 0.90234375\n",
            "epoch: 16 loss: 0.40317184872244405 accuracy: 0.90234375\n",
            "epoch: 17 loss: 0.39671397989876417 accuracy: 0.900390625\n",
            "epoch: 18 loss: 0.39066429925039875 accuracy: 0.900390625\n",
            "epoch: 19 loss: 0.3849842424963377 accuracy: 0.904296875\n",
            "epoch: 20 loss: 0.37964005791771926 accuracy: 0.904296875\n",
            "epoch: 21 loss: 0.37460207921205885 accuracy: 0.904296875\n",
            "epoch: 22 loss: 0.3698441249497796 accuracy: 0.90625\n",
            "epoch: 23 loss: 0.3653429991697381 accuracy: 0.90625\n",
            "epoch: 24 loss: 0.3610780739881875 accuracy: 0.904296875\n",
            "epoch: 25 loss: 0.35703093932649366 accuracy: 0.908203125\n",
            "epoch: 26 loss: 0.3531851078820514 accuracy: 0.908203125\n",
            "epoch: 27 loss: 0.34952576574358374 accuracy: 0.91015625\n",
            "epoch: 28 loss: 0.34603956083466825 accuracy: 0.91015625\n",
            "epoch: 29 loss: 0.3427144227958857 accuracy: 0.91015625\n",
            "epoch: 30 loss: 0.33953940907016883 accuracy: 0.91015625\n",
            "epoch: 31 loss: 0.33650457289393665 accuracy: 0.912109375\n",
            "epoch: 32 loss: 0.3336008496602769 accuracy: 0.912109375\n",
            "epoch: 33 loss: 0.3308199587423132 accuracy: 0.9140625\n",
            "epoch: 34 loss: 0.3281543183716279 accuracy: 0.9140625\n",
            "epoch: 35 loss: 0.3255969715796677 accuracy: 0.9140625\n",
            "epoch: 36 loss: 0.32314152154729486 accuracy: 0.916015625\n",
            "epoch: 37 loss: 0.3207820749833892 accuracy: 0.916015625\n",
            "epoch: 38 loss: 0.31851319237937553 accuracy: 0.9140625\n",
            "epoch: 39 loss: 0.31632984417227206 accuracy: 0.9140625\n",
            "epoch: 40 loss: 0.3142273720018483 accuracy: 0.9140625\n",
            "epoch: 41 loss: 0.31220145437396546 accuracy: 0.9140625\n",
            "epoch: 42 loss: 0.31024807614706273 accuracy: 0.916015625\n",
            "epoch: 43 loss: 0.30836350134598844 accuracy: 0.916015625\n",
            "epoch: 44 loss: 0.306544248880218 accuracy: 0.9140625\n",
            "epoch: 45 loss: 0.304787070804476 accuracy: 0.9140625\n",
            "epoch: 46 loss: 0.3030889328110169 accuracy: 0.9140625\n",
            "epoch: 47 loss: 0.3014469966860038 accuracy: 0.9140625\n",
            "epoch: 48 loss: 0.29985860449893725 accuracy: 0.916015625\n",
            "epoch: 49 loss: 0.29832126432503714 accuracy: 0.916015625\n",
            "epoch: 50 loss: 0.29683263732683857 accuracy: 0.91796875\n",
            "epoch: 51 loss: 0.2953905260437037 accuracy: 0.91796875\n",
            "epoch: 52 loss: 0.2939928637572045 accuracy: 0.91796875\n",
            "epoch: 53 loss: 0.29263770481679935 accuracy: 0.916015625\n",
            "epoch: 54 loss: 0.29132321582442816 accuracy: 0.916015625\n",
            "epoch: 55 loss: 0.29004766758887623 accuracy: 0.916015625\n",
            "epoch: 56 loss: 0.28880942777135177 accuracy: 0.916015625\n",
            "epoch: 57 loss: 0.2876069541528776 accuracy: 0.916015625\n",
            "epoch: 58 loss: 0.28643878846208537 accuracy: 0.9140625\n",
            "epoch: 59 loss: 0.2853035507089247 accuracy: 0.9140625\n",
            "epoch: 60 loss: 0.28419993397588217 accuracy: 0.9140625\n",
            "epoch: 61 loss: 0.2831266996235842 accuracy: 0.9140625\n",
            "epoch: 62 loss: 0.2820826728723293 accuracy: 0.9140625\n",
            "epoch: 63 loss: 0.281066738725166 accuracy: 0.9140625\n",
            "epoch: 64 loss: 0.2800778382017357 accuracy: 0.916015625\n",
            "epoch: 65 loss: 0.2791149648552782 accuracy: 0.916015625\n",
            "epoch: 66 loss: 0.2781771615479901 accuracy: 0.916015625\n",
            "epoch: 67 loss: 0.277263517462432 accuracy: 0.916015625\n",
            "epoch: 68 loss: 0.2763731653288553 accuracy: 0.916015625\n",
            "epoch: 69 loss: 0.2755052788503095 accuracy: 0.916015625\n",
            "epoch: 70 loss: 0.2746590703091173 accuracy: 0.916015625\n",
            "epoch: 71 loss: 0.27383378833985567 accuracy: 0.916015625\n",
            "epoch: 72 loss: 0.2730287158553947 accuracy: 0.916015625\n",
            "epoch: 73 loss: 0.27224316811375754 accuracy: 0.916015625\n",
            "epoch: 74 loss: 0.2714764909147078 accuracy: 0.916015625\n",
            "epoch: 75 loss: 0.27072805891595075 accuracy: 0.916015625\n",
            "epoch: 76 loss: 0.2699972740597381 accuracy: 0.916015625\n",
            "epoch: 77 loss: 0.2692835641014883 accuracy: 0.916015625\n",
            "epoch: 78 loss: 0.26858638123273304 accuracy: 0.916015625\n",
            "epoch: 79 loss: 0.2679052007913965 accuracy: 0.916015625\n",
            "epoch: 80 loss: 0.26723952005297 accuracy: 0.916015625\n",
            "epoch: 81 loss: 0.2665888570967155 accuracy: 0.916015625\n",
            "epoch: 82 loss: 0.2659527497414916 accuracy: 0.916015625\n",
            "epoch: 83 loss: 0.2653307545462567 accuracy: 0.916015625\n",
            "epoch: 84 loss: 0.26472244587069693 accuracy: 0.916015625\n",
            "epoch: 85 loss: 0.2641274149917824 accuracy: 0.916015625\n",
            "epoch: 86 loss: 0.2635452692724131 accuracy: 0.916015625\n",
            "epoch: 87 loss: 0.26297563137858276 accuracy: 0.916015625\n",
            "epoch: 88 loss: 0.2624181385417975 accuracy: 0.916015625\n",
            "epoch: 89 loss: 0.26187244186371395 accuracy: 0.916015625\n",
            "epoch: 90 loss: 0.2613382056602082 accuracy: 0.91796875\n",
            "epoch: 91 loss: 0.2608151068422822 accuracy: 0.91796875\n",
            "epoch: 92 loss: 0.26030283433142126 accuracy: 0.91796875\n",
            "epoch: 93 loss: 0.2598010885071841 accuracy: 0.91796875\n",
            "epoch: 94 loss: 0.2593095806849689 accuracy: 0.916015625\n",
            "epoch: 95 loss: 0.25882803262205073 accuracy: 0.916015625\n",
            "epoch: 96 loss: 0.2583561760501247 accuracy: 0.916015625\n",
            "epoch: 97 loss: 0.25789375223270466 accuracy: 0.916015625\n",
            "epoch: 98 loss: 0.2574405115458556 accuracy: 0.91796875\n",
            "epoch: 99 loss: 0.2569962130808331 accuracy: 0.919921875\n",
            "epoch: 100 loss: 0.2565606242673129 accuracy: 0.919921875\n",
            "epoch: 101 loss: 0.2561335205159718 accuracy: 0.91796875\n",
            "epoch: 102 loss: 0.2557146848792742 accuracy: 0.91796875\n",
            "epoch: 103 loss: 0.2553039077293938 accuracy: 0.91796875\n",
            "epoch: 104 loss: 0.2549009864522688 accuracy: 0.91796875\n",
            "epoch: 105 loss: 0.254505725156853 accuracy: 0.91796875\n",
            "epoch: 106 loss: 0.25411793439870317 accuracy: 0.91796875\n",
            "epoch: 107 loss: 0.25373743091706785 accuracy: 0.91796875\n",
            "epoch: 108 loss: 0.25336403738473123 accuracy: 0.91796875\n",
            "epoch: 109 loss: 0.25299758216988766 accuracy: 0.91796875\n",
            "epoch: 110 loss: 0.2526378991093844 accuracy: 0.91796875\n",
            "epoch: 111 loss: 0.2522848272926992 accuracy: 0.91796875\n",
            "epoch: 112 loss: 0.2519382108560713 accuracy: 0.91796875\n",
            "epoch: 113 loss: 0.25159789878622907 accuracy: 0.91796875\n",
            "epoch: 114 loss: 0.2512637447332025 accuracy: 0.91796875\n",
            "epoch: 115 loss: 0.250935606831732 accuracy: 0.91796875\n",
            "epoch: 116 loss: 0.2506133475308136 accuracy: 0.91796875\n",
            "epoch: 117 loss: 0.2502968334309589 accuracy: 0.91796875\n",
            "epoch: 118 loss: 0.24998593512876244 accuracy: 0.91796875\n",
            "epoch: 119 loss: 0.2496805270683969 accuracy: 0.91796875\n",
            "epoch: 120 loss: 0.24938048739968005 accuracy: 0.919921875\n",
            "epoch: 121 loss: 0.24908569784237528 accuracy: 0.919921875\n",
            "epoch: 122 loss: 0.24879604355641474 accuracy: 0.919921875\n",
            "epoch: 123 loss: 0.24851141301773808 accuracy: 0.919921875\n",
            "epoch: 124 loss: 0.24823169789947158 accuracy: 0.919921875\n",
            "epoch: 125 loss: 0.24795679295818107 accuracy: 0.919921875\n",
            "epoch: 126 loss: 0.24768659592494677 accuracy: 0.919921875\n",
            "epoch: 127 loss: 0.2474210074010217 accuracy: 0.919921875\n",
            "epoch: 128 loss: 0.24715993075785822 accuracy: 0.919921875\n",
            "epoch: 129 loss: 0.24690327204127852 accuracy: 0.919921875\n",
            "epoch: 130 loss: 0.2466509398796052 accuracy: 0.919921875\n",
            "epoch: 131 loss: 0.24640284539554916 accuracy: 0.919921875\n",
            "epoch: 132 loss: 0.24615890212168573 accuracy: 0.919921875\n",
            "epoch: 133 loss: 0.24591902591934428 accuracy: 0.919921875\n",
            "epoch: 134 loss: 0.2456831349007577 accuracy: 0.919921875\n",
            "epoch: 135 loss: 0.24545114935431464 accuracy: 0.919921875\n",
            "epoch: 136 loss: 0.2452229916727718 accuracy: 0.919921875\n",
            "epoch: 137 loss: 0.24499858628429547 accuracy: 0.919921875\n",
            "epoch: 138 loss: 0.24477785958619844 accuracy: 0.919921875\n",
            "epoch: 139 loss: 0.24456073988125035 accuracy: 0.919921875\n",
            "epoch: 140 loss: 0.2443471573164465 accuracy: 0.919921875\n",
            "epoch: 141 loss: 0.24413704382412998 accuracy: 0.91796875\n",
            "epoch: 142 loss: 0.24393033306535364 accuracy: 0.91796875\n",
            "epoch: 143 loss: 0.24372696037538877 accuracy: 0.91796875\n",
            "epoch: 144 loss: 0.24352686271128393 accuracy: 0.91796875\n",
            "epoch: 145 loss: 0.2433299786013893 accuracy: 0.91796875\n",
            "epoch: 146 loss: 0.243136248096752 accuracy: 0.91796875\n",
            "epoch: 147 loss: 0.24294561272431212 accuracy: 0.91796875\n",
            "epoch: 148 loss: 0.24275801544181405 accuracy: 0.91796875\n",
            "epoch: 149 loss: 0.24257340059436483 accuracy: 0.91796875\n",
            "epoch: 150 loss: 0.2423917138725697 accuracy: 0.91796875\n",
            "epoch: 151 loss: 0.2422129022721738 accuracy: 0.91796875\n",
            "epoch: 152 loss: 0.242036914055154 accuracy: 0.91796875\n",
            "epoch: 153 loss: 0.24186369871219657 accuracy: 0.91796875\n",
            "epoch: 154 loss: 0.24169320692650018 accuracy: 0.91796875\n",
            "epoch: 155 loss: 0.2415253905388588 accuracy: 0.91796875\n",
            "epoch: 156 loss: 0.24136020251396237 accuracy: 0.91796875\n",
            "epoch: 157 loss: 0.24119759690787312 accuracy: 0.91796875\n",
            "epoch: 158 loss: 0.24103752883662716 accuracy: 0.91796875\n",
            "epoch: 159 loss: 0.2408799544459111 accuracy: 0.91796875\n",
            "epoch: 160 loss: 0.24072483088178562 accuracy: 0.91796875\n",
            "epoch: 161 loss: 0.24057211626239505 accuracy: 0.91796875\n",
            "epoch: 162 loss: 0.24042176965063808 accuracy: 0.91796875\n",
            "epoch: 163 loss: 0.24027375102775708 accuracy: 0.91796875\n",
            "epoch: 164 loss: 0.24012802126781127 accuracy: 0.91796875\n",
            "epoch: 165 loss: 0.2399845421129957 accuracy: 0.91796875\n",
            "epoch: 166 loss: 0.2398432761497787 accuracy: 0.91796875\n",
            "epoch: 167 loss: 0.239704186785824 accuracy: 0.91796875\n",
            "epoch: 168 loss: 0.2395672382276664 accuracy: 0.91796875\n",
            "epoch: 169 loss: 0.23943239545911302 accuracy: 0.91796875\n",
            "epoch: 170 loss: 0.2392996242203454 accuracy: 0.91796875\n",
            "epoch: 171 loss: 0.2391688909876913 accuracy: 0.91796875\n",
            "epoch: 172 loss: 0.23904016295404595 accuracy: 0.91796875\n",
            "epoch: 173 loss: 0.23891340800991331 accuracy: 0.91796875\n",
            "epoch: 174 loss: 0.23878859472505196 accuracy: 0.91796875\n",
            "epoch: 175 loss: 0.2386656923306942 accuracy: 0.91796875\n",
            "epoch: 176 loss: 0.23854467070232477 accuracy: 0.91796875\n",
            "epoch: 177 loss: 0.23842550034299537 accuracy: 0.91796875\n",
            "epoch: 178 loss: 0.2383081523671566 accuracy: 0.91796875\n",
            "epoch: 179 loss: 0.23819259848498744 accuracy: 0.91796875\n",
            "epoch: 180 loss: 0.23807881098720698 accuracy: 0.91796875\n",
            "epoch: 181 loss: 0.2379667627303469 accuracy: 0.91796875\n",
            "epoch: 182 loss: 0.2378564271224736 accuracy: 0.91796875\n",
            "epoch: 183 loss: 0.23774777810934092 accuracy: 0.91796875\n",
            "epoch: 184 loss: 0.23764079016095793 accuracy: 0.91796875\n",
            "epoch: 185 loss: 0.2375354382585592 accuracy: 0.91796875\n",
            "epoch: 186 loss: 0.2374316978819605 accuracy: 0.91796875\n",
            "epoch: 187 loss: 0.23732954499729317 accuracy: 0.91796875\n",
            "epoch: 188 loss: 0.23722895604509484 accuracy: 0.91796875\n",
            "epoch: 189 loss: 0.23712990792875294 accuracy: 0.91796875\n",
            "epoch: 190 loss: 0.23703237800328028 accuracy: 0.916015625\n",
            "epoch: 191 loss: 0.23693634406442304 accuracy: 0.916015625\n",
            "epoch: 192 loss: 0.23684178433807643 accuracy: 0.916015625\n",
            "epoch: 193 loss: 0.2367486774700097 accuracy: 0.916015625\n",
            "epoch: 194 loss: 0.23665700251588043 accuracy: 0.916015625\n",
            "epoch: 195 loss: 0.23656673893153757 accuracy: 0.916015625\n",
            "epoch: 196 loss: 0.2364778665635946 accuracy: 0.916015625\n",
            "epoch: 197 loss: 0.23639036564027072 accuracy: 0.916015625\n",
            "epoch: 198 loss: 0.23630421676248914 accuracy: 0.916015625\n",
            "epoch: 199 loss: 0.2362194008952227 accuracy: 0.916015625\n",
            "[ 6.15251722e-03  6.15251540e-03  1.07504158e-02  3.46208840e-02\n",
            "  1.77829188e-02 -2.56774974e+00  3.95090184e-04 -6.63332384e-04\n",
            " -1.60389892e-03 -7.41657589e-04  6.91431479e-04  3.63763022e-04\n",
            " -7.59833894e-04  5.29946171e-03 -9.51062628e-03 -2.61895214e-01\n",
            "  3.68980476e-05 -1.36573673e-04 -2.14621035e-04 -5.16081871e-05\n",
            "  7.65991153e-05  5.45654428e-06  8.72041436e-03  4.29729080e-02\n",
            " -2.27618493e-02 -3.34599111e+00  5.21878370e-04 -2.27997061e-03\n",
            " -3.77757219e-03 -1.07419838e-03  7.76240239e-04]\n",
            "(200,)\n",
            "(200,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200,)\n",
            "(200,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469\n",
            "43\n",
            "53\n",
            "4\n",
            "confusion_matrix:\n",
            " [[165  30]\n",
            " [ 13 304]]\n",
            "165 30 13 304\n",
            "training accuracy_lor: 91.6015625 %\n",
            "0.916015625\n",
            "confusion_matrix:\n",
            " [[15  2]\n",
            " [ 2 38]]\n",
            "15 2 2 38\n",
            "testing accuracy_lor: 92.98245614035088 %\n",
            "0.9298245614035088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWJhkrFl7b_F"
      },
      "source": [
        "# sklearn logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVJrwrSP7bdn",
        "outputId": "df314c9c-a447-49c5-c849-8b64eb686894"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression().fit(x_train, y_train)  \n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_train, y_pred = clf.predict(x_train)))\n",
        "TN, FP, FN, TP = confusion_matrix(y_train, clf.predict(x_train)).ravel()\n",
        "training_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"training accuracy_lor:\",training_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_train, y_pred = clf.predict(x_train)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"confusion_matrix:\\n\",confusion_matrix(y_true = y_test, y_pred = clf.predict(x_test)))\n",
        "TN, FP, FN, TP = confusion_matrix(y_test, clf.predict(x_test)).ravel()\n",
        "testing_accuracy_lor = (TP+TN) / (TP+TN+FP+FN)\n",
        "print(TN, FP, FN, TP)\n",
        "print(\"testing accuracy_lor:\",testing_accuracy_lor*100,\"%\")\n",
        "print(accuracy_score(y_true = y_test, y_pred = clf.predict(x_test)))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix:\n",
            " [[182  13]\n",
            " [ 10 307]]\n",
            "182 13 10 307\n",
            "training accuracy_lor: 95.5078125 %\n",
            "0.955078125\n",
            "confusion_matrix:\n",
            " [[16  1]\n",
            " [ 0 40]]\n",
            "16 1 0 40\n",
            "testing accuracy_lor: 98.24561403508771 %\n",
            "0.9824561403508771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCA-Jck87geM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}